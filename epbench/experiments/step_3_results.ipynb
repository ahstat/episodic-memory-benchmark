{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo_filepath = '/filepath/to/gitrepo/episodic-memory-benchmark'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0, 20.00% remaining with issues (4/20), for index: [11, 13, 16, 19].\n",
      "At iteration 1, 15.00% remaining with issues (3/20), for index: [11, 13, 16].\n",
      "At iteration 2, 10.00% remaining with issues (2/20), for index: [13, 16].\n",
      "At iteration 3, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 4, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 5, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 6, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 7, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 8, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At final iteration 9, 5.00% remaining with issues (1/20), for index: [16].\n",
      "itermax reached but some events still did not pass the verification\n",
      "At iteration 0, 33.50% remaining with issues (67/200), for index: [11, 13, 16, 19, 20, 23, 25, 30, 33, 42, 44, 45, 47, 48, 50, 51, 56, 59, 62, 63, 67, 69, 70, 71, 79, 80, 85, 86, 88, 93, 96, 106, 109, 122, 125, 127, 128, 130, 136, 138, 143, 144, 146, 147, 148, 149, 150, 152, 155, 156, 160, 162, 163, 166, 169, 172, 175, 177, 178, 180, 181, 182, 185, 189, 193, 197, 199].\n",
      "At iteration 1, 16.50% remaining with issues (33/200), for index: [11, 13, 16, 42, 44, 56, 59, 67, 79, 80, 93, 96, 106, 122, 127, 128, 130, 136, 143, 144, 146, 147, 150, 156, 160, 162, 163, 166, 169, 172, 175, 182, 193].\n",
      "At iteration 2, 10.50% remaining with issues (21/200), for index: [13, 16, 42, 44, 56, 67, 79, 93, 96, 106, 143, 144, 146, 150, 156, 160, 162, 166, 169, 182, 193].\n",
      "At iteration 3, 7.50% remaining with issues (15/200), for index: [16, 42, 44, 56, 67, 93, 96, 106, 143, 144, 146, 156, 160, 182, 193].\n",
      "At iteration 4, 5.50% remaining with issues (11/200), for index: [16, 42, 44, 56, 67, 93, 146, 156, 160, 182, 193].\n",
      "At iteration 5, 4.50% remaining with issues (9/200), for index: [16, 56, 67, 93, 146, 156, 160, 182, 193].\n",
      "At iteration 6, 3.00% remaining with issues (6/200), for index: [16, 56, 67, 156, 160, 182].\n",
      "At iteration 7, 2.50% remaining with issues (5/200), for index: [16, 56, 67, 156, 160].\n",
      "At iteration 8, 2.00% remaining with issues (4/200), for index: [16, 56, 156, 160].\n",
      "At final iteration 9, 2.00% remaining with issues (4/200), for index: [16, 56, 156, 160].\n",
      "itermax reached but some events still did not pass the verification\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from epbench.src.generation.benchmark_generation_wrapper import BenchmarkGenerationWrapper\n",
    "book_parameters = {'indexing': 'default', 'nb_summaries': 0}\n",
    "data_folder = Path(git_repo_filepath) / 'epbench' / 'data'\n",
    "env_file = Path(git_repo_filepath) / '.env'\n",
    "\n",
    "# Generation with Claude -- 20 events\n",
    "prompt_parameters = {'nb_events': 20, 'name_universe': 'default', 'name_styles': 'default', 'seed': 0, 'distribution_events': {'name': 'geometric', 'param': 0.1}}\n",
    "model_parameters = {'model_name': 'claude-3-5-sonnet-20240620', 'max_new_tokens': 4096, 'itermax': 10}\n",
    "benchmark_claude_default_20 = BenchmarkGenerationWrapper(prompt_parameters, model_parameters, book_parameters, data_folder, env_file)\n",
    "\n",
    "# Generation with Claude -- 200 events\n",
    "prompt_parameters = {'nb_events': 200, 'name_universe': 'default', 'name_styles': 'default', 'seed': 0, 'distribution_events': {'name': 'geometric', 'param': 0.1}}\n",
    "model_parameters = {'model_name': 'claude-3-5-sonnet-20240620', 'max_new_tokens': 4096, 'itermax': 10}\n",
    "benchmark_claude_default_200 = BenchmarkGenerationWrapper(prompt_parameters, model_parameters, book_parameters, data_folder, env_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 experiments\n",
      "Document with 10397 tokens, answer with prompting using with gpt-4o-mini-2024-07-18\n",
      "Document with 10397 tokens, answer with prompting using with gpt-4o-2024-08-06\n",
      "Document with 10397 tokens, answer with prompting using with claude-3-haiku-20240307\n",
      "Document with 10397 tokens, answer with prompting using with claude-3-5-sonnet-20240620\n",
      "Document with 10397 tokens, answer with prompting using with o1-mini\n",
      "Document with 10397 tokens, answer with prompting using with llama-3.1-405b-instruct\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4o-mini-2024-07-18\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4o-2024-08-06\n",
      "Document with 102870 tokens, answer with prompting using with claude-3-haiku-20240307\n",
      "Document with 102870 tokens, answer with prompting using with claude-3-5-sonnet-20240620\n",
      "Document with 102870 tokens, answer with prompting using with o1-mini\n",
      "Document with 102870 tokens, answer with prompting using with llama-3.1-405b-instruct\n",
      "Document with 10397 tokens, answer with rag using with gpt-4o-mini-2024-07-18 (paragraph chunks)\n",
      "Document with 10397 tokens, answer with rag using with gpt-4o-2024-08-06 (paragraph chunks)\n",
      "Document with 10397 tokens, answer with rag using with claude-3-haiku-20240307 (paragraph chunks)\n",
      "Document with 10397 tokens, answer with rag using with claude-3-5-sonnet-20240620 (paragraph chunks)\n",
      "Document with 102870 tokens, answer with rag using with gpt-4o-mini-2024-07-18 (paragraph chunks)\n",
      "Document with 102870 tokens, answer with rag using with gpt-4o-2024-08-06 (paragraph chunks)\n",
      "Document with 102870 tokens, answer with rag using with claude-3-haiku-20240307 (paragraph chunks)\n",
      "Document with 102870 tokens, answer with rag using with claude-3-5-sonnet-20240620 (paragraph chunks)\n",
      "Document with 10397 tokens, answer with ftuning using with gpt-4o-mini-2024-07-18\n",
      "Document with 102870 tokens, answer with ftuning using with gpt-4o-mini-2024-07-18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_nb_events</th>\n",
       "      <th>answering_kind</th>\n",
       "      <th>answering_model_name</th>\n",
       "      <th>answering_embedding_chunk</th>\n",
       "      <th>book_model_name</th>\n",
       "      <th>evaluation_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>llama-3.1-405b-instruct</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>llama-3.1-405b-instruct</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>rag</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>rag</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>rag</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>rag</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200</td>\n",
       "      <td>rag</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>200</td>\n",
       "      <td>rag</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200</td>\n",
       "      <td>rag</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>rag</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>ftuning</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>200</td>\n",
       "      <td>ftuning</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_nb_events answering_kind        answering_model_name  \\\n",
       "0               20      prompting      gpt-4o-mini-2024-07-18   \n",
       "1               20      prompting           gpt-4o-2024-08-06   \n",
       "2               20      prompting     claude-3-haiku-20240307   \n",
       "3               20      prompting  claude-3-5-sonnet-20240620   \n",
       "4               20      prompting                     o1-mini   \n",
       "5               20      prompting     llama-3.1-405b-instruct   \n",
       "6              200      prompting      gpt-4o-mini-2024-07-18   \n",
       "7              200      prompting           gpt-4o-2024-08-06   \n",
       "8              200      prompting     claude-3-haiku-20240307   \n",
       "9              200      prompting  claude-3-5-sonnet-20240620   \n",
       "10             200      prompting                     o1-mini   \n",
       "11             200      prompting     llama-3.1-405b-instruct   \n",
       "12              20            rag      gpt-4o-mini-2024-07-18   \n",
       "13              20            rag           gpt-4o-2024-08-06   \n",
       "14              20            rag     claude-3-haiku-20240307   \n",
       "15              20            rag  claude-3-5-sonnet-20240620   \n",
       "16             200            rag      gpt-4o-mini-2024-07-18   \n",
       "17             200            rag           gpt-4o-2024-08-06   \n",
       "18             200            rag     claude-3-haiku-20240307   \n",
       "19             200            rag  claude-3-5-sonnet-20240620   \n",
       "20              20        ftuning      gpt-4o-mini-2024-07-18   \n",
       "21             200        ftuning      gpt-4o-mini-2024-07-18   \n",
       "\n",
       "   answering_embedding_chunk             book_model_name  \\\n",
       "0                        n/a  claude-3-5-sonnet-20240620   \n",
       "1                        n/a  claude-3-5-sonnet-20240620   \n",
       "2                        n/a  claude-3-5-sonnet-20240620   \n",
       "3                        n/a  claude-3-5-sonnet-20240620   \n",
       "4                        n/a  claude-3-5-sonnet-20240620   \n",
       "5                        n/a  claude-3-5-sonnet-20240620   \n",
       "6                        n/a  claude-3-5-sonnet-20240620   \n",
       "7                        n/a  claude-3-5-sonnet-20240620   \n",
       "8                        n/a  claude-3-5-sonnet-20240620   \n",
       "9                        n/a  claude-3-5-sonnet-20240620   \n",
       "10                       n/a  claude-3-5-sonnet-20240620   \n",
       "11                       n/a  claude-3-5-sonnet-20240620   \n",
       "12                 paragraph  claude-3-5-sonnet-20240620   \n",
       "13                 paragraph  claude-3-5-sonnet-20240620   \n",
       "14                 paragraph  claude-3-5-sonnet-20240620   \n",
       "15                 paragraph  claude-3-5-sonnet-20240620   \n",
       "16                 paragraph  claude-3-5-sonnet-20240620   \n",
       "17                 paragraph  claude-3-5-sonnet-20240620   \n",
       "18                 paragraph  claude-3-5-sonnet-20240620   \n",
       "19                 paragraph  claude-3-5-sonnet-20240620   \n",
       "20                       n/a  claude-3-5-sonnet-20240620   \n",
       "21                       n/a  claude-3-5-sonnet-20240620   \n",
       "\n",
       "                                    evaluation_object  \n",
       "0   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "1   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "2   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "3   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "4   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "5   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "6   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "7   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "8   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "9   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "10  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "11  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "12  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "13  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "14  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "15  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "16  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "17  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "18  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "19  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "20  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "21  <epbench.src.evaluation.evaluation_wrapper.Eva...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "from epbench.src.evaluation.precomputed_results import get_precomputed_results\n",
    "\n",
    "experiments = [\n",
    "    # in-context, book with 20 events\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-mini-2024-07-18'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-2024-08-06'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'claude-3-haiku-20240307'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'claude-3-5-sonnet-20240620'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'o1-mini'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'llama-3.1-405b-instruct'},\n",
    "    #{'book_nb_events': 20, 'answering_kind': 'prompting', 'answering_model_name': 'o1-preview'}, # existing but discarded since only done for the short book\n",
    "    # in-context, book with 200 events\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-mini-2024-07-18'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-2024-08-06'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'claude-3-haiku-20240307'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'claude-3-5-sonnet-20240620'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'o1-mini'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'llama-3.1-405b-instruct'},\n",
    "    # RAG, book with 20 events\n",
    "    {'book_nb_events': 20,  'answering_kind': 'rag',       'answering_model_name': 'gpt-4o-mini-2024-07-18',     'answering_embedding_chunk': 'paragraph'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'rag',       'answering_model_name': 'gpt-4o-2024-08-06',          'answering_embedding_chunk': 'paragraph'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'rag',       'answering_model_name': 'claude-3-haiku-20240307',    'answering_embedding_chunk': 'paragraph'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'rag',       'answering_model_name': 'claude-3-5-sonnet-20240620', 'answering_embedding_chunk': 'paragraph'},\n",
    "    #{'book_nb_events': 20, 'answering_kind': 'rag',       'answering_model_name': 'gpt-4o-mini-2024-07-18',     'answering_embedding_chunk': 'chapter'}, # used for ablation\n",
    "    #{'book_nb_events': 20, 'answering_kind': 'rag',       'answering_model_name': 'gpt-4o-2024-08-06',          'answering_embedding_chunk': 'chapter'}, # used for ablation\n",
    "    #{'book_nb_events': 20, 'answering_kind': 'rag',       'answering_model_name': 'claude-3-haiku-20240307',    'answering_embedding_chunk': 'chapter'}, # used for ablation\n",
    "    #{'book_nb_events': 20, 'answering_kind': 'rag',       'answering_model_name': 'claude-3-5-sonnet-20240620', 'answering_embedding_chunk': 'chapter'}, # used for ablation\n",
    "    # RAG, book with 200 events\n",
    "    {'book_nb_events': 200, 'answering_kind': 'rag',       'answering_model_name': 'gpt-4o-mini-2024-07-18',     'answering_embedding_chunk': 'paragraph'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'rag',       'answering_model_name': 'gpt-4o-2024-08-06',          'answering_embedding_chunk': 'paragraph'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'rag',       'answering_model_name': 'claude-3-haiku-20240307',    'answering_embedding_chunk': 'paragraph'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'rag',       'answering_model_name': 'claude-3-5-sonnet-20240620', 'answering_embedding_chunk': 'paragraph'},\n",
    "    #{'book_nb_events': 200,'answering_kind': 'rag',       'answering_model_name': 'gpt-4o-mini-2024-07-18',     'answering_embedding_chunk': 'chapter'}, # used for ablation\n",
    "    #{'book_nb_events': 200,'answering_kind': 'rag',       'answering_model_name': 'gpt-4o-2024-08-06',          'answering_embedding_chunk': 'chapter'}, # used for ablation\n",
    "    #{'book_nb_events': 200,'answering_kind': 'rag',       'answering_model_name': 'claude-3-haiku-20240307',    'answering_embedding_chunk': 'chapter'}, # used for ablation\n",
    "    #{'book_nb_events': 200,'answering_kind': 'rag',       'answering_model_name': 'claude-3-5-sonnet-20240620', 'answering_embedding_chunk': 'chapter'}, # used for ablation\n",
    "    # Fine tuning, book with 20 events\n",
    "    {'book_nb_events': 20,  'answering_kind': 'ftuning',   'answering_model_name': 'gpt-4o-mini-2024-07-18'},\n",
    "    #{'book_nb_events': 20, 'answering_kind': 'ftuning',   'answering_model_name': 'gpt-4o-2024-08-06'}, # existing but discarded since only done for the short book\n",
    "    # Fine tuning, book with 200 events\n",
    "    {'book_nb_events': 200, 'answering_kind': 'ftuning',   'answering_model_name': 'gpt-4o-mini-2024-07-18'},\n",
    "]\n",
    "\n",
    "for i in range(len(experiments)):\n",
    "    if not 'answering_embedding_chunk' in experiments[i]:\n",
    "        experiments[i]['answering_embedding_chunk'] = 'n/a'\n",
    "    experiments[i]['book_model_name'] = 'claude-3-5-sonnet-20240620'\n",
    "\n",
    "print(f\"{len(experiments)} experiments\")\n",
    "\n",
    "all_benchmarks = {'benchmark_claude_default_20': benchmark_claude_default_20,\n",
    "                  'benchmark_claude_default_200': benchmark_claude_default_200}\n",
    "\n",
    "df = get_precomputed_results(experiments, env_file, data_folder, all_benchmarks)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of table with comparison of the different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins_items_correct_answer</th>\n",
       "      <th>count</th>\n",
       "      <th>(prompting, gpt-4o-mini-2024-07-18, n/a)</th>\n",
       "      <th>(prompting, gpt-4o-2024-08-06, n/a)</th>\n",
       "      <th>(prompting, claude-3-haiku-20240307, n/a)</th>\n",
       "      <th>(prompting, claude-3-5-sonnet-20240620, n/a)</th>\n",
       "      <th>(prompting, o1-mini, n/a)</th>\n",
       "      <th>(prompting, llama-3.1-405b-instruct, n/a)</th>\n",
       "      <th>(rag, gpt-4o-mini-2024-07-18, paragraph)</th>\n",
       "      <th>(rag, gpt-4o-2024-08-06, paragraph)</th>\n",
       "      <th>(rag, claude-3-haiku-20240307, paragraph)</th>\n",
       "      <th>(rag, claude-3-5-sonnet-20240620, paragraph)</th>\n",
       "      <th>(ftuning, gpt-4o-mini-2024-07-18, n/a)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0.51±0.50</td>\n",
       "      <td>0.84±0.37</td>\n",
       "      <td>0.84±0.37</td>\n",
       "      <td>0.92±0.27</td>\n",
       "      <td>0.97±0.16</td>\n",
       "      <td>0.80±0.40</td>\n",
       "      <td>0.63±0.49</td>\n",
       "      <td>0.82±0.39</td>\n",
       "      <td>0.71±0.45</td>\n",
       "      <td>0.91±0.28</td>\n",
       "      <td>0.00±0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.54±0.46</td>\n",
       "      <td>0.81±0.38</td>\n",
       "      <td>0.39±0.48</td>\n",
       "      <td>0.35±0.48</td>\n",
       "      <td>0.05±0.19</td>\n",
       "      <td>0.49±0.47</td>\n",
       "      <td>0.60±0.46</td>\n",
       "      <td>0.60±0.46</td>\n",
       "      <td>0.57±0.47</td>\n",
       "      <td>0.59±0.47</td>\n",
       "      <td>0.83±0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0.44±0.36</td>\n",
       "      <td>0.60±0.31</td>\n",
       "      <td>0.37±0.30</td>\n",
       "      <td>0.35±0.33</td>\n",
       "      <td>0.12±0.24</td>\n",
       "      <td>0.38±0.33</td>\n",
       "      <td>0.60±0.34</td>\n",
       "      <td>0.55±0.33</td>\n",
       "      <td>0.59±0.33</td>\n",
       "      <td>0.59±0.35</td>\n",
       "      <td>0.37±0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-5</td>\n",
       "      <td>98</td>\n",
       "      <td>0.47±0.27</td>\n",
       "      <td>0.57±0.21</td>\n",
       "      <td>0.37±0.28</td>\n",
       "      <td>0.32±0.25</td>\n",
       "      <td>0.12±0.19</td>\n",
       "      <td>0.40±0.25</td>\n",
       "      <td>0.59±0.26</td>\n",
       "      <td>0.55±0.28</td>\n",
       "      <td>0.58±0.26</td>\n",
       "      <td>0.59±0.27</td>\n",
       "      <td>0.28±0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6+</td>\n",
       "      <td>60</td>\n",
       "      <td>0.50±0.17</td>\n",
       "      <td>0.53±0.14</td>\n",
       "      <td>0.38±0.19</td>\n",
       "      <td>0.41±0.20</td>\n",
       "      <td>0.24±0.19</td>\n",
       "      <td>0.45±0.20</td>\n",
       "      <td>0.62±0.22</td>\n",
       "      <td>0.59±0.21</td>\n",
       "      <td>0.59±0.25</td>\n",
       "      <td>0.62±0.25</td>\n",
       "      <td>0.19±0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bins_items_correct_answer  count (prompting, gpt-4o-mini-2024-07-18, n/a)  \\\n",
       "0                         0    150                                0.51±0.50   \n",
       "1                         1    150                                0.54±0.46   \n",
       "2                         2     90                                0.44±0.36   \n",
       "3                       3-5     98                                0.47±0.27   \n",
       "4                        6+     60                                0.50±0.17   \n",
       "\n",
       "  (prompting, gpt-4o-2024-08-06, n/a)  \\\n",
       "0                           0.84±0.37   \n",
       "1                           0.81±0.38   \n",
       "2                           0.60±0.31   \n",
       "3                           0.57±0.21   \n",
       "4                           0.53±0.14   \n",
       "\n",
       "  (prompting, claude-3-haiku-20240307, n/a)  \\\n",
       "0                                 0.84±0.37   \n",
       "1                                 0.39±0.48   \n",
       "2                                 0.37±0.30   \n",
       "3                                 0.37±0.28   \n",
       "4                                 0.38±0.19   \n",
       "\n",
       "  (prompting, claude-3-5-sonnet-20240620, n/a) (prompting, o1-mini, n/a)  \\\n",
       "0                                    0.92±0.27                 0.97±0.16   \n",
       "1                                    0.35±0.48                 0.05±0.19   \n",
       "2                                    0.35±0.33                 0.12±0.24   \n",
       "3                                    0.32±0.25                 0.12±0.19   \n",
       "4                                    0.41±0.20                 0.24±0.19   \n",
       "\n",
       "  (prompting, llama-3.1-405b-instruct, n/a)  \\\n",
       "0                                 0.80±0.40   \n",
       "1                                 0.49±0.47   \n",
       "2                                 0.38±0.33   \n",
       "3                                 0.40±0.25   \n",
       "4                                 0.45±0.20   \n",
       "\n",
       "  (rag, gpt-4o-mini-2024-07-18, paragraph)  \\\n",
       "0                                0.63±0.49   \n",
       "1                                0.60±0.46   \n",
       "2                                0.60±0.34   \n",
       "3                                0.59±0.26   \n",
       "4                                0.62±0.22   \n",
       "\n",
       "  (rag, gpt-4o-2024-08-06, paragraph)  \\\n",
       "0                           0.82±0.39   \n",
       "1                           0.60±0.46   \n",
       "2                           0.55±0.33   \n",
       "3                           0.55±0.28   \n",
       "4                           0.59±0.21   \n",
       "\n",
       "  (rag, claude-3-haiku-20240307, paragraph)  \\\n",
       "0                                 0.71±0.45   \n",
       "1                                 0.57±0.47   \n",
       "2                                 0.59±0.33   \n",
       "3                                 0.58±0.26   \n",
       "4                                 0.59±0.25   \n",
       "\n",
       "  (rag, claude-3-5-sonnet-20240620, paragraph)  \\\n",
       "0                                    0.91±0.28   \n",
       "1                                    0.59±0.47   \n",
       "2                                    0.59±0.35   \n",
       "3                                    0.59±0.27   \n",
       "4                                    0.62±0.25   \n",
       "\n",
       "  (ftuning, gpt-4o-mini-2024-07-18, n/a)  \n",
       "0                              0.00±0.00  \n",
       "1                              0.83±0.35  \n",
       "2                              0.37±0.32  \n",
       "3                              0.28±0.21  \n",
       "4                              0.19±0.07  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epbench.src.results.average_groups import extract_groups\n",
    "nb_events = 200 # select the book of interest (either 20 or 200)\n",
    "relative_to = ['get', 'bins_items_correct_answer'] # select the grouped elements as a list among:\n",
    "# 'get': type of question, among 'all' (simple recall questions), 'latest' (latest state questions), or 'chronological' (chronological questions)\n",
    "# 'bins_items_correct_answer': number of events for this question, binned into {0}, {1}, {2}, {3,4,5}, {6+} chapters\n",
    "# 'cue': type of cue for this question, e.g. (*,*,*,c)\n",
    "# 'retrieval_type': type of trace for this question, e.g. 'Spaces'\n",
    "df_results = extract_groups(df, nb_events, relative_to) # group the results according to `relative_to`\n",
    "\n",
    "# Further filtering, e.g. for selecting only the simple recall questions:\n",
    "df_results = df_results[df_results['get'] == 'all'].drop('get', axis = 1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CD plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['o1-mini', 'gpt-4o', 'llama-3.1', 'cl-3.5-sonnet', 'gpt-4o-mini',\n",
      "       'cl-3.5-sonnet (rag)', 'cl-3-haiku', 'gpt-4o (rag)', 'cl-3-haiku (rag)',\n",
      "       'gpt-4o-mini (rag)', 'gpt-4o-mini (ftuning)'],\n",
      "      dtype='object')\n",
      "[1, 0]\n",
      "[1, 2, 3]\n",
      "[4, 6, 5]\n",
      "[4, 6, 7]\n",
      "[8, 9]\n",
      "Index(['gpt-4o', 'cl-3.5-sonnet (rag)', 'gpt-4o (rag)', 'gpt-4o-mini (rag)',\n",
      "       'cl-3-haiku (rag)', 'llama-3.1', 'cl-3-haiku', 'gpt-4o-mini',\n",
      "       'cl-3.5-sonnet', 'gpt-4o-mini (ftuning)', 'o1-mini'],\n",
      "      dtype='object')\n",
      "[0, 1]\n",
      "[2, 3, 4]\n",
      "[5, 8, 6, 7]\n",
      "[9, 10]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "def get_short_name_from_model_name(answering_model_name, answering_kind, answering_embedding_chunk):\n",
    "    if 'gpt-4o-mini' in answering_model_name:\n",
    "        model_name = 'gpt-4o-mini'\n",
    "    elif 'gpt-4o' in answering_model_name:\n",
    "        model_name = 'gpt-4o'\n",
    "    elif 'claude-3-5-sonnet' in answering_model_name:\n",
    "        model_name = 'cl-3.5-sonnet'\n",
    "    elif 'claude-3-haiku' in answering_model_name:\n",
    "        model_name = 'cl-3-haiku'\n",
    "    elif 'o1-mini' in answering_model_name:\n",
    "        model_name = 'o1-mini'\n",
    "    elif 'o1-preview' in answering_model_name:\n",
    "        model_name = 'o1-preview'\n",
    "    elif 'llama-3.1-405b-instruct' in answering_model_name:\n",
    "        model_name = 'llama-3.1'\n",
    "    else:\n",
    "        raise ValueError('unknown model')\n",
    "    \n",
    "    if answering_kind == 'prompting':\n",
    "        output = model_name\n",
    "    elif answering_kind == 'rag':\n",
    "        if answering_embedding_chunk == 'chapter':\n",
    "            output = f\"{model_name} (rag, {answering_embedding_chunk[0]})\"\n",
    "        else: \n",
    "            output = f\"{model_name} (rag)\"\n",
    "    elif answering_kind == 'ftuning':\n",
    "        output = f\"{model_name} (ftuning)\"\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_short_name(i, df):\n",
    "    res = df.iloc[i][['answering_kind', 'answering_model_name', 'answering_embedding_chunk']]\n",
    "    model_name = get_short_name_from_model_name(res['answering_model_name'], res['answering_kind'], res['answering_embedding_chunk'])\n",
    "    return model_name\n",
    "\n",
    "for nb_events in [20,200]:\n",
    "    results_list = []\n",
    "    for i in range(len(df)):\n",
    "        if (df['book_nb_events'].iloc[i] == nb_events):\n",
    "            res_cur = df['evaluation_object'].iloc[i]\n",
    "            res_cur = res_cur.df_generated_evaluations[['f1_score_lenient']].rename(columns = {'f1_score_lenient': get_short_name(i, df)})\n",
    "            results_list.append(res_cur)\n",
    "\n",
    "    results = pd.concat(results_list, axis = 1)\n",
    "    result_long = results.reset_index().melt(id_vars='index', var_name='method', value_name='f1_score').rename(columns={'index': 'question'})\n",
    "    df_perf = result_long.rename(columns={'method': 'classifier_name', 'f1_score': 'accuracy', 'question': 'dataset_name'})\n",
    "    from epbench.src.results.cd import draw_cd_diagram\n",
    "    output_file = Path(git_repo_filepath) / 'epbench' / 'plots' / f'cd_{nb_events}_rebuttal.pdf'\n",
    "    draw_cd_diagram(df_perf=df_perf, title='F1-score (rank)', labels=True, output_file = output_file, width = 6, fontsize = 12, textspace = 0.5, lowv=4,highv=8)\n",
    "\n",
    "# CD plots are saved into `Path(git_repo_filepath) / 'epbench' / 'plots' / f'cd_{nb_events}.pdf'``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result for a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results for ('prompting', 'gpt-4o-2024-08-06', 'n/a')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bins_items_correct_answer</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3-5</th>\n",
       "      <th>6+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cue</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(*, *, *, c)</th>\n",
       "      <td>1.00±0.00 (15)</td>\n",
       "      <td>0.93±0.26 (15)</td>\n",
       "      <td>0.65±0.35 (12)</td>\n",
       "      <td>0.65±0.20 (15)</td>\n",
       "      <td>0.56±0.16 (15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(*, *, ent, *)</th>\n",
       "      <td>1.00±0.00 (15)</td>\n",
       "      <td>0.97±0.13 (15)</td>\n",
       "      <td>0.56±0.26 (9)</td>\n",
       "      <td>0.61±0.28 (15)</td>\n",
       "      <td>0.59±0.19 (15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(*, s, *, *)</th>\n",
       "      <td>1.00±0.00 (15)</td>\n",
       "      <td>0.93±0.26 (15)</td>\n",
       "      <td>0.79±0.23 (15)</td>\n",
       "      <td>0.61±0.15 (15)</td>\n",
       "      <td>0.50±0.08 (15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(t, *, *, *)</th>\n",
       "      <td>0.80±0.41 (15)</td>\n",
       "      <td>1.00±0.00 (15)</td>\n",
       "      <td>0.65±0.18 (12)</td>\n",
       "      <td>0.54±0.20 (15)</td>\n",
       "      <td>0.47±0.09 (15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(*, *, ent, c)</th>\n",
       "      <td>0.90±0.32 (10)</td>\n",
       "      <td>0.90±0.32 (10)</td>\n",
       "      <td>0.65±0.39 (10)</td>\n",
       "      <td>0.55±0.16 (10)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(*, s, *, c)</th>\n",
       "      <td>1.00±0.00 (10)</td>\n",
       "      <td>0.70±0.48 (10)</td>\n",
       "      <td>0.48±0.30 (10)</td>\n",
       "      <td>0.61±0.20 (10)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(*, s, ent, *)</th>\n",
       "      <td>0.80±0.42 (10)</td>\n",
       "      <td>0.65±0.47 (10)</td>\n",
       "      <td>0.38±0.40 (10)</td>\n",
       "      <td>0.43±0.20 (8)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(t, *, *, c)</th>\n",
       "      <td>0.70±0.48 (10)</td>\n",
       "      <td>0.80±0.42 (10)</td>\n",
       "      <td>0.52±0.24 (10)</td>\n",
       "      <td>0.48±0.24 (10)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(t, s, *, *)</th>\n",
       "      <td>0.80±0.42 (10)</td>\n",
       "      <td>0.40±0.52 (10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(t, *, ent, *)</th>\n",
       "      <td>0.40±0.52 (10)</td>\n",
       "      <td>0.60±0.52 (10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(*, s, ent, c)</th>\n",
       "      <td>0.40±0.55 (5)</td>\n",
       "      <td>1.00±0.00 (5)</td>\n",
       "      <td>0.42±0.12 (2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(t, *, ent, c)</th>\n",
       "      <td>0.40±0.55 (5)</td>\n",
       "      <td>0.60±0.55 (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(t, s, *, c)</th>\n",
       "      <td>1.00±0.00 (5)</td>\n",
       "      <td>0.80±0.45 (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(t, s, ent, *)</th>\n",
       "      <td>0.80±0.45 (5)</td>\n",
       "      <td>0.80±0.45 (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(t, s, ent, c)</th>\n",
       "      <td>1.00±0.00 (10)</td>\n",
       "      <td>0.70±0.32 (10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bins_items_correct_answer               0               1               2  \\\n",
       "cue                                                                         \n",
       "(*, *, *, c)               1.00±0.00 (15)  0.93±0.26 (15)  0.65±0.35 (12)   \n",
       "(*, *, ent, *)             1.00±0.00 (15)  0.97±0.13 (15)   0.56±0.26 (9)   \n",
       "(*, s, *, *)               1.00±0.00 (15)  0.93±0.26 (15)  0.79±0.23 (15)   \n",
       "(t, *, *, *)               0.80±0.41 (15)  1.00±0.00 (15)  0.65±0.18 (12)   \n",
       "(*, *, ent, c)             0.90±0.32 (10)  0.90±0.32 (10)  0.65±0.39 (10)   \n",
       "(*, s, *, c)               1.00±0.00 (10)  0.70±0.48 (10)  0.48±0.30 (10)   \n",
       "(*, s, ent, *)             0.80±0.42 (10)  0.65±0.47 (10)  0.38±0.40 (10)   \n",
       "(t, *, *, c)               0.70±0.48 (10)  0.80±0.42 (10)  0.52±0.24 (10)   \n",
       "(t, s, *, *)               0.80±0.42 (10)  0.40±0.52 (10)             NaN   \n",
       "(t, *, ent, *)             0.40±0.52 (10)  0.60±0.52 (10)             NaN   \n",
       "(*, s, ent, c)              0.40±0.55 (5)   1.00±0.00 (5)   0.42±0.12 (2)   \n",
       "(t, *, ent, c)              0.40±0.55 (5)   0.60±0.55 (5)             NaN   \n",
       "(t, s, *, c)                1.00±0.00 (5)   0.80±0.45 (5)             NaN   \n",
       "(t, s, ent, *)              0.80±0.45 (5)   0.80±0.45 (5)             NaN   \n",
       "(t, s, ent, c)             1.00±0.00 (10)  0.70±0.32 (10)             NaN   \n",
       "\n",
       "bins_items_correct_answer             3-5              6+  \n",
       "cue                                                        \n",
       "(*, *, *, c)               0.65±0.20 (15)  0.56±0.16 (15)  \n",
       "(*, *, ent, *)             0.61±0.28 (15)  0.59±0.19 (15)  \n",
       "(*, s, *, *)               0.61±0.15 (15)  0.50±0.08 (15)  \n",
       "(t, *, *, *)               0.54±0.20 (15)  0.47±0.09 (15)  \n",
       "(*, *, ent, c)             0.55±0.16 (10)             NaN  \n",
       "(*, s, *, c)               0.61±0.20 (10)             NaN  \n",
       "(*, s, ent, *)              0.43±0.20 (8)             NaN  \n",
       "(t, *, *, c)               0.48±0.24 (10)             NaN  \n",
       "(t, s, *, *)                          NaN             NaN  \n",
       "(t, *, ent, *)                        NaN             NaN  \n",
       "(*, s, ent, c)                        NaN             NaN  \n",
       "(t, *, ent, c)                        NaN             NaN  \n",
       "(t, s, *, c)                          NaN             NaN  \n",
       "(t, s, ent, *)                        NaN             NaN  \n",
       "(t, s, ent, c)                        NaN             NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result table for a single model, based on the following parameters\n",
    "nb_events = 200\n",
    "relative_to = ['get', 'cue', 'bins_items_correct_answer'] # 'cue_size' is also available\n",
    "model_of_interest = ('prompting', 'gpt-4o-2024-08-06', 'n/a')\n",
    "\n",
    "df_results = extract_groups(df, nb_events, relative_to)\n",
    "df_results = df_results[df_results['get'] == 'all']\n",
    "df_results = df_results[relative_to + ['count', model_of_interest]]\n",
    "df_results\n",
    "df_results['value'] = [f\"{x} ({y})\" for x, y in zip(df_results[model_of_interest], df_results['count'])]\n",
    "df_results.pivot(index='cue', columns='bins_items_correct_answer', values='value')\n",
    "df_results_pivoted = df_results.pivot(index='cue', columns='bins_items_correct_answer', values='value')\n",
    "# reordering\n",
    "df_results_pivoted['nb_cues'] = [4-x.count('*') for x in df_results_pivoted.index]\n",
    "df_results_pivoted = df_results_pivoted.sort_values('nb_cues')\n",
    "print(f\"results for {model_of_interest}\")\n",
    "df_results_pivoted.drop('nb_cues', axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kendall's tau results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cl-3-haiku (rag)</th>\n",
       "      <th>gpt-4o-mini (rag)</th>\n",
       "      <th>cl-3.5-sonnet (rag)</th>\n",
       "      <th>gpt-4o (rag)</th>\n",
       "      <th>gpt-4o</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <th>cl-3-haiku</th>\n",
       "      <th>cl-3.5-sonnet</th>\n",
       "      <th>llama-3.1</th>\n",
       "      <th>o1-mini</th>\n",
       "      <th>gpt-4o-mini (ftuning)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Latest</th>\n",
       "      <td>23%</td>\n",
       "      <td>36%</td>\n",
       "      <td>32%</td>\n",
       "      <td>23%</td>\n",
       "      <td>36%</td>\n",
       "      <td>13%</td>\n",
       "      <td>17%</td>\n",
       "      <td>18%</td>\n",
       "      <td>26%</td>\n",
       "      <td>7%</td>\n",
       "      <td>23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>18%</td>\n",
       "      <td>13%</td>\n",
       "      <td>13%</td>\n",
       "      <td>8%</td>\n",
       "      <td>10%</td>\n",
       "      <td>8%</td>\n",
       "      <td>5%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kendall τ</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cl-3-haiku (rag) gpt-4o-mini (rag) cl-3.5-sonnet (rag) gpt-4o (rag)  \\\n",
       "Latest                 23%               36%                 32%          23%   \n",
       "All                    18%               13%                 13%           8%   \n",
       "Kendall τ             0.43              0.93                 0.6          1.0   \n",
       "\n",
       "          gpt-4o gpt-4o-mini cl-3-haiku cl-3.5-sonnet llama-3.1 o1-mini  \\\n",
       "Latest       36%         13%        17%           18%       26%      7%   \n",
       "All          10%          8%         5%            0%        0%      0%   \n",
       "Kendall τ    0.5        0.33        1.0           NaN       NaN     NaN   \n",
       "\n",
       "          gpt-4o-mini (ftuning)  \n",
       "Latest                      23%  \n",
       "All                          0%  \n",
       "Kendall τ                   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_events = 200\n",
    "\n",
    "# 1. adding the `All` and the `Kendall τ` results (in total, there are 39 questions involving temporal aspects with >= 2 linked events)\n",
    "kendall_tau_results = pd.concat([x.kendall_summaries_for_this_experiment for x in df['evaluation_object']]).reset_index(drop=True)\n",
    "kendall_tau_results = pd.concat([df, kendall_tau_results], axis = 1)\n",
    "kendall_tau_results['%_exact_match_set_gt_with_pred2'] = [int(x[:-1]) for x in kendall_tau_results['%_exact_match_set_gt_with_pred']]\n",
    "kendall_tau_results['All'] = [f\"{round(u/d * 100)}%\" for u,d in zip(kendall_tau_results['#exact_match_set_gt_with_pred'], kendall_tau_results['#gt_with_len_2+'])]\n",
    "kendall_tau_results['Kendall τ'] = [float(x.split('±')[0]) for x in kendall_tau_results['tau_exact_match_set_gt_with_pred']]\n",
    "kendall_tau_results['name'] = [get_short_name(i, kendall_tau_results) for i in range(len(kendall_tau_results))]\n",
    "kendall_tau_results = kendall_tau_results[kendall_tau_results['book_nb_events'] == nb_events]\n",
    "kendall_tau_results = kendall_tau_results.drop('book_nb_events', axis = 1).reset_index(drop = True)\n",
    "kendall_tau_results = kendall_tau_results.sort_values(['%_exact_match_set_gt_with_pred2', 'Kendall τ'], ascending = False)\n",
    "kendall_tau_results = kendall_tau_results[['name', 'All', 'Kendall τ']]\n",
    "kendall_tau_results = kendall_tau_results.set_index('name').transpose()\n",
    "\n",
    "# 2. adding the `Latest` results, by looking at the correct result for bins with >= 2 linked events\n",
    "from epbench.src.results.average_groups import extract_groups\n",
    "relative_to = ['get', 'bins_items_correct_answer']\n",
    "df_results = extract_groups(df, nb_events, relative_to, 'f1_score_lenient')\n",
    "df_results = df_results[df_results['get'] == 'latest']\n",
    "df_results = df_results[df_results['bins_items_correct_answer'].isin(['2', '3-5', '6+'])]\n",
    "# extract the average performance float element\n",
    "for col in df_results.columns:\n",
    "   if col not in ['get', 'bins_items_correct_answer', 'count']:\n",
    "       df_results[col] = df_results[col].str.extract(r'([\\d.]+)').astype(float)\n",
    "# extract the percentage by computing sum(count*average) over all bins with >= 2 correct answers, for each model\n",
    "result = {}\n",
    "for col in df_results.columns:\n",
    "   if col not in ['get', 'bins_items_correct_answer', 'count']:\n",
    "       answering_kind, answering_model_name, answering_embedding_chunk = col\n",
    "       current_short_name = get_short_name_from_model_name(answering_model_name, answering_kind, answering_embedding_chunk)\n",
    "       result[current_short_name] = f\"{round(100*(df_results[col] * df_results['count']).sum()/df_results['count'].sum())}%\"\n",
    "new_row = pd.Series({col: result[col] if col in result else None for col in kendall_tau_results.columns}, name='Latest')\n",
    "# finally add those `Latest` results as a third row\n",
    "kendall_tau_results = pd.concat([kendall_tau_results, new_row.to_frame().T])\n",
    "kendall_tau_results = kendall_tau_results.loc[['Latest', 'All', 'Kendall τ']]\n",
    "\n",
    "# 3. reorder to follow exactly the table in the paper\n",
    "kendall_tau_results = kendall_tau_results[['cl-3-haiku (rag)', 'gpt-4o-mini (rag)', 'cl-3.5-sonnet (rag)',\n",
    "                                             'gpt-4o (rag)', 'gpt-4o', 'gpt-4o-mini', 'cl-3-haiku', 'cl-3.5-sonnet',\n",
    "                                             'llama-3.1', 'o1-mini', 'gpt-4o-mini (ftuning)']]\n",
    "kendall_tau_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['get', 'bins_items_correct_answer', 'cue', 'gpt-4o-mini', 'gpt-4o',\n",
      "       'cl-3-haiku', 'cl-3.5-sonnet', 'o1-mini', 'llama-3.1',\n",
      "       'gpt-4o-mini\\n(rag)', 'gpt-4o\\n(rag)', 'cl-3-haiku\\n(rag)',\n",
      "       'cl-3.5-sonnet\\n(rag)', 'gpt-4o-mini\\n(ftuning)'],\n",
      "      dtype='object')\n",
      "Index(['get', 'bins_items_correct_answer', 'cue', 'gpt-4o-mini', 'gpt-4o',\n",
      "       'cl-3-haiku', 'cl-3.5-sonnet', 'o1-mini', 'llama-3.1',\n",
      "       'gpt-4o-mini\\n(rag)', 'gpt-4o\\n(rag)', 'cl-3-haiku\\n(rag)',\n",
      "       'cl-3.5-sonnet\\n(rag)', 'gpt-4o-mini\\n(ftuning)'],\n",
      "      dtype='object')\n",
      "Index(['get', 'bins_items_correct_answer', 'cue', 'gpt-4o-mini', 'gpt-4o',\n",
      "       'cl-3-haiku', 'cl-3.5-sonnet', 'o1-mini', 'llama-3.1',\n",
      "       'gpt-4o-mini\\n(rag)', 'gpt-4o\\n(rag)', 'cl-3-haiku\\n(rag)',\n",
      "       'cl-3.5-sonnet\\n(rag)', 'gpt-4o-mini\\n(ftuning)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from epbench.src.results.heatmaps import plot_clust\n",
    "nb_events = 200\n",
    "relative_to = ['get', 'bins_items_correct_answer', 'cue']\n",
    "for bin in ['0', '1', '2']:\n",
    "    if bin == '2':\n",
    "        figsize = (5, 2)\n",
    "    else:\n",
    "        figsize=(4.5, 2)\n",
    "    fig = plot_clust(df, nb_events, relative_to, figsize=figsize, only_bins = [bin])\n",
    "    fig.savefig(Path(git_repo_filepath) / 'epbench' / 'plots' / f'heatmap_{bin}_rebuttal.pdf', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poster plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['get', 'bins_items_correct_answer', 'gpt-4o-mini', 'gpt-4o',\n",
      "       'cl-3-haiku', 'cl-3.5-sonnet', 'o1-mini', 'llama-3.1',\n",
      "       'gpt-4o-mini\\n(rag)', 'gpt-4o\\n(rag)', 'cl-3-haiku\\n(rag)',\n",
      "       'cl-3.5-sonnet\\n(rag)', 'gpt-4o-mini\\n(ftuning)'],\n",
      "      dtype='object')\n",
      "Index(['get', 'bins_items_correct_answer', 'gpt-4o-mini', 'gpt-4o',\n",
      "       'cl-3-haiku', 'cl-3.5-sonnet', 'o1-mini', 'llama-3.1',\n",
      "       'gpt-4o-mini\\n(rag)', 'gpt-4o\\n(rag)', 'cl-3-haiku\\n(rag)',\n",
      "       'cl-3.5-sonnet\\n(rag)', 'gpt-4o-mini\\n(ftuning)'],\n",
      "      dtype='object')\n",
      "Index(['get', 'bins_items_correct_answer', 'gpt-4o-mini', 'gpt-4o',\n",
      "       'cl-3-haiku', 'cl-3.5-sonnet', 'o1-mini', 'llama-3.1',\n",
      "       'gpt-4o-mini\\n(rag)', 'gpt-4o\\n(rag)', 'cl-3-haiku\\n(rag)',\n",
      "       'cl-3.5-sonnet\\n(rag)', 'gpt-4o-mini\\n(ftuning)'],\n",
      "      dtype='object')\n",
      "Index(['get', 'bins_items_correct_answer', 'gpt-4o-mini', 'gpt-4o',\n",
      "       'cl-3-haiku', 'cl-3.5-sonnet', 'o1-mini', 'llama-3.1',\n",
      "       'gpt-4o-mini\\n(rag)', 'gpt-4o\\n(rag)', 'cl-3-haiku\\n(rag)',\n",
      "       'cl-3.5-sonnet\\n(rag)', 'gpt-4o-mini\\n(ftuning)'],\n",
      "      dtype='object')\n",
      "Index(['get', 'bins_items_correct_answer', 'gpt-4o-mini', 'gpt-4o',\n",
      "       'cl-3-haiku', 'cl-3.5-sonnet', 'o1-mini', 'llama-3.1',\n",
      "       'gpt-4o-mini\\n(rag)', 'gpt-4o\\n(rag)', 'cl-3-haiku\\n(rag)',\n",
      "       'cl-3.5-sonnet\\n(rag)', 'gpt-4o-mini\\n(ftuning)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from epbench.src.results.average_groups import extract_groups\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm, ListedColormap\n",
    "from warnings import catch_warnings, filterwarnings\n",
    "\n",
    "from epbench.src.results.heatmaps import get_short_name2\n",
    "\n",
    "def plot_clust0(df, nb_events, relative_to, figsize=(16, 20), only_bins = None):\n",
    "    with catch_warnings():\n",
    "        filterwarnings('ignore')\n",
    "        \n",
    "        df_results = extract_groups(df, nb_events, relative_to)\n",
    "\n",
    "        df_results = df_results[df_results['get'] == 'all']\n",
    "        if only_bins is not None:\n",
    "            df_results = df_results[df_results['bins_items_correct_answer'].isin(only_bins)]\n",
    "\n",
    "\n",
    "        data = df_results.loc[:, df_results.columns != 'count']\n",
    "\n",
    "\n",
    "        data['bins_items_correct_answer'] = pd.Categorical(data['bins_items_correct_answer'], ['0', '1', '2', '3-5', '6+'])\n",
    "\n",
    "        data.columns = [get_short_name2(x) for x in data.columns]\n",
    "        \n",
    "        print(data.columns)\n",
    "\n",
    "        data = data[['get', 'bins_items_correct_answer', \n",
    "                    'gpt-4o', 'llama-3.1', 'cl-3-haiku', 'gpt-4o-mini', 'cl-3.5-sonnet', 'o1-mini',\n",
    "                    'cl-3.5-sonnet\\n(rag)', 'gpt-4o\\n(rag)', 'gpt-4o-mini\\n(rag)', 'cl-3-haiku\\n(rag)', \n",
    "                    'gpt-4o-mini\\n(ftuning)']]\n",
    "        \n",
    "        data.columns = ['get', 'bins_items_correct_answer', \n",
    "                    'gpt-4o', 'llama-3.1', 'cl-3-haiku', 'gpt-4o-mini', 'cl-3.5-sonnet', 'o1-mini',\n",
    "                    'cl-3.5-sonnet', 'gpt-4o', 'gpt-4o-mini', 'cl-3-haiku', \n",
    "                    'gpt-4o-mini']\n",
    "\n",
    "        for col in reversed(relative_to):\n",
    "            data = data.sort_values(by=col, ascending=True)\n",
    "            data = data.loc[:, data.columns != col]\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        my_colors = ['darkred', 'red', 'orange', 'green', 'white']\n",
    "        my_cmap = ListedColormap(my_colors)\n",
    "        bounds = [-1, 0.49999, 0.69, 0.80, 0.90, 1]\n",
    "        my_norm = BoundaryNorm(bounds, ncolors=len(my_colors))\n",
    "\n",
    "        def remove_second_part(x):\n",
    "            return round(float(x.split(\"±\")[0]), 2) # rounding one digit!\n",
    "        data = data.applymap(remove_second_part)\n",
    "\n",
    "        return data\n",
    "\n",
    "def plot_clust1(data, nb_events, relative_to, figsize=(16, 20), only_bins = None):\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    legend = False\n",
    "    if only_bins[0] == '2':\n",
    "        legend = True\n",
    "\n",
    "    colors = [\n",
    "        (68/255, 1/255, 84/255),\n",
    "        (72/255, 36/255, 117/255),\n",
    "        (65/255, 68/255, 135/255),\n",
    "        (53/255, 95/255, 141/255),\n",
    "        (42/255, 120/255, 142/255),\n",
    "        (33/255, 145/255, 140/255),\n",
    "        (34/255, 168/255, 132/255),\n",
    "        (68/255, 191/255, 112/255),\n",
    "        (122/255, 209/255, 81/255),\n",
    "        (189/255, 223/255, 38/255),\n",
    "        (253/255, 231/255, 37/255)]\n",
    "    \n",
    "    positions = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "    custom_cmap = LinearSegmentedColormap.from_list(\"custom\", list(zip(positions, colors)))\n",
    "\n",
    "    my_plot = sns.heatmap(data, annot=True, fmt='.2f', cmap=custom_cmap, cbar=legend, vmin=0, vmax=1) # 'RdYlGn'\n",
    "    fig = my_plot.get_figure()\n",
    "\n",
    "    return fig\n",
    "    \n",
    "data = []\n",
    "nb_events = 200\n",
    "relative_to = ['get', 'bins_items_correct_answer']\n",
    "for bin in ['0', '1', '2', '3-5', '6+']:\n",
    "    if bin == '2':\n",
    "        figsize = (5, 2)\n",
    "    else:\n",
    "        figsize=(4.5, 2)\n",
    "    data.append(plot_clust0(df, nb_events, relative_to, figsize=figsize, only_bins = [bin]))\n",
    "\n",
    "data = pd.concat(data, axis = 0)\n",
    "data.index = ['0', '1', '2', '3-5', '6+']\n",
    "data = data.transpose()\n",
    "data\n",
    "\n",
    "figsize=(4, 3.5)\n",
    "bin = '2'\n",
    "fig = plot_clust1(data, nb_events, relative_to, figsize=figsize, only_bins = [bin])\n",
    "\n",
    "fig.savefig(Path(git_repo_filepath) / 'epbench' / 'plots' / f'heatmap_poster.pdf', bbox_inches='tight') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
