{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo_filepath = '/filepath/to/gitrepo/episodic-memory-benchmark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation with Claude -- 200 events\n",
      "At iteration 0, 33.50% remaining with issues (67/200), for index: [11, 13, 16, 19, 20, 23, 25, 30, 33, 42, 44, 45, 47, 48, 50, 51, 56, 59, 62, 63, 67, 69, 70, 71, 79, 80, 85, 86, 88, 93, 96, 106, 109, 122, 125, 127, 128, 130, 136, 138, 143, 144, 146, 147, 148, 149, 150, 152, 155, 156, 160, 162, 163, 166, 169, 172, 175, 177, 178, 180, 181, 182, 185, 189, 193, 197, 199].\n",
      "At iteration 1, 16.50% remaining with issues (33/200), for index: [11, 13, 16, 42, 44, 56, 59, 67, 79, 80, 93, 96, 106, 122, 127, 128, 130, 136, 143, 144, 146, 147, 150, 156, 160, 162, 163, 166, 169, 172, 175, 182, 193].\n",
      "At iteration 2, 10.50% remaining with issues (21/200), for index: [13, 16, 42, 44, 56, 67, 79, 93, 96, 106, 143, 144, 146, 150, 156, 160, 162, 166, 169, 182, 193].\n",
      "At iteration 3, 7.50% remaining with issues (15/200), for index: [16, 42, 44, 56, 67, 93, 96, 106, 143, 144, 146, 156, 160, 182, 193].\n",
      "At iteration 4, 5.50% remaining with issues (11/200), for index: [16, 42, 44, 56, 67, 93, 146, 156, 160, 182, 193].\n",
      "At iteration 5, 4.50% remaining with issues (9/200), for index: [16, 56, 67, 93, 146, 156, 160, 182, 193].\n",
      "At iteration 6, 3.00% remaining with issues (6/200), for index: [16, 56, 67, 156, 160, 182].\n",
      "At iteration 7, 2.50% remaining with issues (5/200), for index: [16, 56, 67, 156, 160].\n",
      "At iteration 8, 2.00% remaining with issues (4/200), for index: [16, 56, 156, 160].\n",
      "At final iteration 9, 2.00% remaining with issues (4/200), for index: [16, 56, 156, 160].\n",
      "itermax reached but some events still did not pass the verification\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from epbench.src.generation.benchmark_generation_wrapper import BenchmarkGenerationWrapper\n",
    "book_parameters = {'indexing': 'default', 'nb_summaries': 0}\n",
    "data_folder = Path(git_repo_filepath) / 'epbench' / 'data'\n",
    "env_file = Path(git_repo_filepath) / '.env'\n",
    "\n",
    "print(\"Generation with Claude -- 200 events\")\n",
    "prompt_parameters = {'nb_events': 200, 'name_universe': 'default', 'name_styles': 'default', 'seed': 0, 'distribution_events': {'name': 'geometric', 'param': 0.1}}\n",
    "model_parameters = {'model_name': 'claude-3-5-sonnet-20240620', 'max_new_tokens': 4096, 'itermax': 10}\n",
    "benchmark_claude_200 = BenchmarkGenerationWrapper(prompt_parameters, model_parameters, book_parameters, data_folder, env_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 experiments\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4o-mini-2024-07-18\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4o-2024-08-06\n",
      "Document with 102870 tokens, answer with prompting using with claude-3-haiku-20240307\n",
      "Document with 102870 tokens, answer with prompting using with claude-3-5-sonnet-20240620\n",
      "Document with 102870 tokens, answer with prompting using with o1-mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_nb_events</th>\n",
       "      <th>answering_kind</th>\n",
       "      <th>answering_model_name</th>\n",
       "      <th>answering_embedding_chunk</th>\n",
       "      <th>book_model_name</th>\n",
       "      <th>evaluation_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_nb_events answering_kind        answering_model_name  \\\n",
       "0             200      prompting      gpt-4o-mini-2024-07-18   \n",
       "1             200      prompting           gpt-4o-2024-08-06   \n",
       "2             200      prompting     claude-3-haiku-20240307   \n",
       "3             200      prompting  claude-3-5-sonnet-20240620   \n",
       "4             200      prompting                     o1-mini   \n",
       "\n",
       "  answering_embedding_chunk             book_model_name  \\\n",
       "0                       n/a  claude-3-5-sonnet-20240620   \n",
       "1                       n/a  claude-3-5-sonnet-20240620   \n",
       "2                       n/a  claude-3-5-sonnet-20240620   \n",
       "3                       n/a  claude-3-5-sonnet-20240620   \n",
       "4                       n/a  claude-3-5-sonnet-20240620   \n",
       "\n",
       "                                   evaluation_object  \n",
       "0  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "1  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "2  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "3  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "4  <epbench.src.evaluation.evaluation_wrapper.Eva...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "from epbench.src.evaluation.precomputed_results import get_precomputed_results\n",
    "\n",
    "experiments = [\n",
    "    # in-context, book with 200 events\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-mini-2024-07-18'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-2024-08-06'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'claude-3-haiku-20240307'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'claude-3-5-sonnet-20240620'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'o1-mini'}\n",
    "]\n",
    "\n",
    "for i in range(len(experiments)):\n",
    "    if not 'answering_embedding_chunk' in experiments[i]:\n",
    "        experiments[i]['answering_embedding_chunk'] = 'n/a'\n",
    "    experiments[i]['book_model_name'] = 'claude-3-5-sonnet-20240620'\n",
    "\n",
    "print(f\"{len(experiments)} experiments\")\n",
    "\n",
    "all_benchmarks = {'benchmark_claude_default_200': benchmark_claude_200}\n",
    "\n",
    "df = get_precomputed_results(experiments, env_file, data_folder, all_benchmarks)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 24 questions with 0 matching events, 150 (16.0%) produced incorrect answers.\n",
      "The 24 failed zero-event questions can be categorized into two types (see Table 11 in the appendix for details):\n",
      "Inner questions (17 cases):\n",
      "- Questions constructed using elements present in the book\n",
      "- Majority (14/17) involve entity-based queries\n",
      "Outer questions (7 cases):\n",
      "- Questions using at least one element from outside the book (sampled from the unused universe)\n",
      "- All involve temporal elements\n",
      "Consistent cue patterns: (t, *, *, *), (t, *, *, c), (t, *, ent, *)\n"
     ]
    }
   ],
   "source": [
    "i=1 # only considering the hallucinations for gpt-4o-2024-08-06\n",
    "df_generated_evaluations = df.iloc[i]['evaluation_object'].df_generated_evaluations\n",
    "df_generated_evaluations_0 = df_generated_evaluations[df_generated_evaluations['bins_items_correct_answer'] == '0']\n",
    "df_generated_evaluations_0 = df_generated_evaluations_0[df_generated_evaluations_0['get'] == 'all']\n",
    "\n",
    "df_generated_evaluations_0 = df_generated_evaluations_0[['q_idx',\n",
    "       'cue', 'cue_completed', 'retrieval_type',\n",
    "       'llm_answer', 'predicted_items', 'explanation', 'f1_score_lenient', 'debug_changed',\n",
    "       'debug_existing_change']]\n",
    "\n",
    "nb_questions_with_0 = len(df_generated_evaluations_0) # 150\n",
    "df_generated_evaluations_0_fail = df_generated_evaluations_0[df_generated_evaluations_0['f1_score_lenient'] < 1]\n",
    "nb_questions_with_0_fail = len(df_generated_evaluations_0_fail) # 24\n",
    "\n",
    "df_generated_evaluations_0_fail = df_generated_evaluations_0_fail[['q_idx', 'cue', 'cue_completed', 'retrieval_type', 'llm_answer', 'predicted_items', 'debug_changed',\n",
    "       'debug_existing_change']]\n",
    "\n",
    "nb_questions_with_0_fail_inner = len(df_generated_evaluations_0_fail[df_generated_evaluations_0_fail['debug_existing_change'] == True]) # 17\n",
    "nb_questions_with_0_fail_outer = len(df_generated_evaluations_0_fail[df_generated_evaluations_0_fail['debug_existing_change'] == False]) # 7\n",
    "\n",
    "# elements involving entity queries for the inner questions \n",
    "import numpy as np\n",
    "res = df_generated_evaluations_0_fail[df_generated_evaluations_0_fail['debug_existing_change'] == True][['cue']].value_counts()\n",
    "nb_inner_with_entity_queries = np.sum([v for k,v in zip(res.index.tolist(), res.values) if 'ent' in k[0] ]) # 14\n",
    "\n",
    "# elements involving temporal queries for the outer questions \n",
    "import numpy as np\n",
    "res2 = df_generated_evaluations_0_fail[df_generated_evaluations_0_fail['debug_existing_change'] == False][['cue']].value_counts()\n",
    "nb_outer_with_temporal_queries = np.sum([v for k,v in zip(res.index.tolist(), res2.values) if 't' in k[0] ]) # 14\n",
    "\n",
    "print(f\"Of the {nb_questions_with_0_fail} questions with 0 matching events, {nb_questions_with_0} ({100*nb_questions_with_0_fail/nb_questions_with_0}%) produced incorrect answers.\")\n",
    "print(f\"The {nb_questions_with_0_fail} failed zero-event questions can be categorized into two types (see Table 11 in the appendix for details):\")\n",
    "print(f\"Inner questions ({nb_questions_with_0_fail_inner} cases):\")\n",
    "print(f\"- Questions constructed using elements present in the book\") # by design\n",
    "print(f\"- Majority ({nb_inner_with_entity_queries}/{nb_questions_with_0_fail_inner}) involve entity-based queries\")\n",
    "print(f\"Outer questions ({nb_questions_with_0_fail_outer} cases):\")\n",
    "print(f\"- Questions using at least one element from outside the book (sampled from the unused universe)\") # by design\n",
    "if(nb_outer_with_temporal_queries == nb_questions_with_0_fail_outer):\n",
    "       print(f\"- All involve temporal elements\")\n",
    "print(f\"Consistent cue patterns: {', '.join([k[0] for k in res2.index.tolist()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_idx</th>\n",
       "      <th>cue</th>\n",
       "      <th>cue_completed</th>\n",
       "      <th>retrieval_type</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>predicted_items</th>\n",
       "      <th>debug_changed</th>\n",
       "      <th>debug_existing_change</th>\n",
       "      <th>percentage_in_book</th>\n",
       "      <th>len_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>16</td>\n",
       "      <td>(t, *, *, c)</td>\n",
       "      <td>({April 09, 2026}, *, *, {Charity Gala})</td>\n",
       "      <td>Spaces</td>\n",
       "      <td>The events related to the Charity Gala on Apri...</td>\n",
       "      <td>[Lincoln Center, High Line]</td>\n",
       "      <td>{content, location, entity}</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>16</td>\n",
       "      <td>(t, *, *, c)</td>\n",
       "      <td>({April 09, 2026}, *, *, {Chess Championship})</td>\n",
       "      <td>Spaces</td>\n",
       "      <td>The events related to the Chess Championship o...</td>\n",
       "      <td>[Lincoln Center, High Line]</td>\n",
       "      <td>{content}</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>14</td>\n",
       "      <td>(t, *, ent, *)</td>\n",
       "      <td>({April 09, 2026}, *, {Zoe Rivera}, *)</td>\n",
       "      <td>Spaces</td>\n",
       "      <td>The events involving Zoe Rivera on April 09, 2...</td>\n",
       "      <td>[American Museum of Natural History, High Line]</td>\n",
       "      <td>{content, location, entity}</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>15</td>\n",
       "      <td>(t, *, ent, *)</td>\n",
       "      <td>({April 09, 2026}, *, {Zoe Rivera}, *)</td>\n",
       "      <td>Event contents</td>\n",
       "      <td>On April 09, 2026, Zoe Rivera was involved in ...</td>\n",
       "      <td>[Astronomy Night]</td>\n",
       "      <td>{content, location, entity}</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>2</td>\n",
       "      <td>(t, *, *, *)</td>\n",
       "      <td>({August 24, 2024}, *, *, *)</td>\n",
       "      <td>Event contents</td>\n",
       "      <td>On August 24, 2024, three key events took plac...</td>\n",
       "      <td>[Storytelling Festival, Carnival, Murder Myste...</td>\n",
       "      <td>{date, location, entity}</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>1</td>\n",
       "      <td>(t, *, *, *)</td>\n",
       "      <td>({August 24, 2024}, *, *, *)</td>\n",
       "      <td>Entities</td>\n",
       "      <td>The events on August 24, 2024, involved the fo...</td>\n",
       "      <td>[Maya Smith, Julian Ross, Mila Gonzalez, Scarl...</td>\n",
       "      <td>{date, location, entity}</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0</td>\n",
       "      <td>(t, *, *, *)</td>\n",
       "      <td>({August 24, 2024}, *, *, *)</td>\n",
       "      <td>Spaces</td>\n",
       "      <td>On August 24, 2024, the unique locations where...</td>\n",
       "      <td>[American Museum of Natural History, One World...</td>\n",
       "      <td>{date, location, entity}</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     q_idx             cue                                   cue_completed  \\\n",
       "510     16    (t, *, *, c)        ({April 09, 2026}, *, *, {Charity Gala})   \n",
       "511     16    (t, *, *, c)  ({April 09, 2026}, *, *, {Chess Championship})   \n",
       "561     14  (t, *, ent, *)          ({April 09, 2026}, *, {Zoe Rivera}, *)   \n",
       "566     15  (t, *, ent, *)          ({April 09, 2026}, *, {Zoe Rivera}, *)   \n",
       "632      2    (t, *, *, *)                    ({August 24, 2024}, *, *, *)   \n",
       "637      1    (t, *, *, *)                    ({August 24, 2024}, *, *, *)   \n",
       "642      0    (t, *, *, *)                    ({August 24, 2024}, *, *, *)   \n",
       "\n",
       "     retrieval_type                                         llm_answer  \\\n",
       "510          Spaces  The events related to the Charity Gala on Apri...   \n",
       "511          Spaces  The events related to the Chess Championship o...   \n",
       "561          Spaces  The events involving Zoe Rivera on April 09, 2...   \n",
       "566  Event contents  On April 09, 2026, Zoe Rivera was involved in ...   \n",
       "632  Event contents  On August 24, 2024, three key events took plac...   \n",
       "637        Entities  The events on August 24, 2024, involved the fo...   \n",
       "642          Spaces  On August 24, 2024, the unique locations where...   \n",
       "\n",
       "                                       predicted_items  \\\n",
       "510                        [Lincoln Center, High Line]   \n",
       "511                        [Lincoln Center, High Line]   \n",
       "561    [American Museum of Natural History, High Line]   \n",
       "566                                  [Astronomy Night]   \n",
       "632  [Storytelling Festival, Carnival, Murder Myste...   \n",
       "637  [Maya Smith, Julian Ross, Mila Gonzalez, Scarl...   \n",
       "642  [American Museum of Natural History, One World...   \n",
       "\n",
       "                   debug_changed debug_existing_change  percentage_in_book  \\\n",
       "510  {content, location, entity}                 False                 1.0   \n",
       "511                    {content}                 False                 1.0   \n",
       "561  {content, location, entity}                 False                 1.0   \n",
       "566  {content, location, entity}                 False                 1.0   \n",
       "632     {date, location, entity}                 False                 1.0   \n",
       "637     {date, location, entity}                 False                 1.0   \n",
       "642     {date, location, entity}                 False                 1.0   \n",
       "\n",
       "     len_answer  \n",
       "510           2  \n",
       "511           2  \n",
       "561           2  \n",
       "566           1  \n",
       "632           3  \n",
       "637           4  \n",
       "642           3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Small manual corrections, since the LLM-as-a-judge machinery would be more complex\n",
    "df_generated_evaluations_0_fail_outer = df_generated_evaluations_0_fail[df_generated_evaluations_0_fail['debug_existing_change'] == False]\n",
    "#print(df_generated_evaluations_0_fail_outer.iloc[3]['llm_answer']) # Astronomy night\n",
    "df_generated_evaluations_0_fail_outer['predicted_items'].iloc[3] = ['Astronomy Night']\n",
    "#print(df_generated_evaluations_0_fail_outer.iloc[4]['llm_answer']) # ['Storytelling Festival', 'Carnival', 'Murder Mystery Dinner']\n",
    "df_generated_evaluations_0_fail_outer['predicted_items'].iloc[4] = ['Storytelling Festival', 'Carnival', 'Murder Mystery Dinner']\n",
    "\n",
    "def get_used_elements(retrieval_type, benchmark_claude_200):\n",
    "    if retrieval_type == \"Times\":\n",
    "        return benchmark_claude_200.df_book_groundtruth['date'].unique()\n",
    "    elif retrieval_type == \"Spaces\":\n",
    "        return benchmark_claude_200.df_book_groundtruth['location'].unique()\n",
    "    elif retrieval_type == \"Entities\":\n",
    "        return benchmark_claude_200.df_book_groundtruth['entity'].unique()\n",
    "    elif retrieval_type == \"Event contents\":\n",
    "        return benchmark_claude_200.df_book_groundtruth['content'].unique()\n",
    "    else:\n",
    "        raise ValueError('unknown retrieval type')\n",
    "\n",
    "import numpy as np\n",
    "def adding_percentage_columns(df_generated_evaluations_0_fail):\n",
    "    res = []\n",
    "    res2 = []\n",
    "    for k in range(len(df_generated_evaluations_0_fail)):\n",
    "        retrieval_type = df_generated_evaluations_0_fail.iloc[k]['retrieval_type']\n",
    "        res.append(np.mean([x in get_used_elements(retrieval_type, benchmark_claude_200) for x in df_generated_evaluations_0_fail.iloc[k]['predicted_items']]))\n",
    "        res2.append(len([x for x in df_generated_evaluations_0_fail.iloc[k]['predicted_items']]))\n",
    "\n",
    "    df_generated_evaluations_0_fail['percentage_in_book'] = res\n",
    "    df_generated_evaluations_0_fail['len_answer'] = res2\n",
    "    return df_generated_evaluations_0_fail\n",
    "\n",
    "df_generated_evaluations_0_fail_outer = adding_percentage_columns(df_generated_evaluations_0_fail_outer)\n",
    "\n",
    "df_generated_evaluations_0_fail_outer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         chapter                date        location       entity  \\\n",
      "chapter                                                             \n",
      "162          162      March 23, 2024  Lincoln Center  Bella Brown   \n",
      "172          172  September 22, 2026  Lincoln Center    Noah Wood   \n",
      "\n",
      "                 content                                      post_entities  \\\n",
      "chapter                                                                       \n",
      "162         Fashion Show  {Matthew Wolf, Bruno Bourne, Thea Merchant, Mi...   \n",
      "172      Astronomy Night  {Gianluca Nunez, Madeleine Combs, Zechariah Nunn}   \n",
      "\n",
      "         n_date  n_location  n_entity  n_content  raw_generated_paragraph_idx  \\\n",
      "chapter                                                                         \n",
      "162          13           2         3         17                          165   \n",
      "172           8           2         3         10                          175   \n",
      "\n",
      "         nb_paragraphs     style  idx_t  idx_s  idx_e  idx_c  \n",
      "chapter                                                       \n",
      "162                  5  thriller      2      1      4      3  \n",
      "172                  7   fantasy      3      5      1      1  \n",
      "         chapter               date                     location  \\\n",
      "chapter                                                            \n",
      "25            25      June 14, 2025              Brooklyn Museum   \n",
      "58            58      June 14, 2025               Trinity Church   \n",
      "69            69      June 14, 2025            Queensboro Bridge   \n",
      "120          120  November 13, 2026       One World Trade Center   \n",
      "121          121  February 22, 2025  Snug Harbor Cultural Center   \n",
      "175          175    August 24, 2026                    High Line   \n",
      "\n",
      "                  entity                content  \\\n",
      "chapter                                           \n",
      "25         Mila Gonzalez  Murder Mystery Dinner   \n",
      "58         Noah Williams  Murder Mystery Dinner   \n",
      "69         Brooklyn Ross  Murder Mystery Dinner   \n",
      "120      Scarlett Thomas  Murder Mystery Dinner   \n",
      "121          Julian Ross  Murder Mystery Dinner   \n",
      "175        Samuel Parker  Murder Mystery Dinner   \n",
      "\n",
      "                                             post_entities  n_date  \\\n",
      "chapter                                                              \n",
      "25       {Emilia Hooks, Hamza Avila, Koa Berlin, Raven ...      10   \n",
      "58       {Mae Nestor, Aaron Godwin, Sasha Hamrick, Remy...      10   \n",
      "69             {Colton Cyphers, Corey Goetz, Avah Dunning}      10   \n",
      "120         {Azriel Franklin, Thatcher Rendon, Remy Duran}      10   \n",
      "121      {Carson Gardner, Angelo Funderburk, Yousef For...       2   \n",
      "175            {Darius Nesbitt, Rosalie Cole, Talia Brito}       4   \n",
      "\n",
      "         n_location  n_entity  n_content  raw_generated_paragraph_idx  \\\n",
      "chapter                                                                 \n",
      "25                3         9          6                           25   \n",
      "58               10         7          6                           59   \n",
      "69                8         9          6                           70   \n",
      "120              14        15          6                          121   \n",
      "121               7        17          6                          122   \n",
      "175              17        10          6                          178   \n",
      "\n",
      "         nb_paragraphs      style  idx_t  idx_s  idx_e  idx_c  \n",
      "chapter                                                        \n",
      "25                   6    tragedy      3      1      2      2  \n",
      "58                   2    mystery      2      1      2      1  \n",
      "69                   9  detective      5      9      6      8  \n",
      "120                  5     horror      1      5      5      2  \n",
      "121                  2     comedy      2      1      2      2  \n",
      "175                  6    fantasy      5      4      5      1  \n",
      "Empty DataFrame\n",
      "Columns: [chapter, date, location, entity, content, post_entities, n_date, n_location, n_entity, n_content, raw_generated_paragraph_idx, nb_paragraphs, style, idx_t, idx_s, idx_e, idx_c]\n",
      "Index: []\n",
      "         chapter            date                            location  \\\n",
      "chapter                                                                \n",
      "14            14  April 09, 2026         Snug Harbor Cultural Center   \n",
      "22            22  April 09, 2026                     Brooklyn Museum   \n",
      "45            45  April 09, 2026                           High Line   \n",
      "67            67  April 09, 2026                   Statue of Liberty   \n",
      "78            78  April 09, 2026  American Museum of Natural History   \n",
      "88            88  April 09, 2026                   Queensboro Bridge   \n",
      "96            96  April 09, 2026                        Ellis Island   \n",
      "102          102  April 09, 2026              One World Trade Center   \n",
      "136          136  April 09, 2026              Washington Square Park   \n",
      "153          153  April 09, 2026                  Van Cortlandt Park   \n",
      "182          182  April 09, 2026                 Bethpage State Park   \n",
      "192          192  April 09, 2026                      Trinity Church   \n",
      "\n",
      "                  entity                   content  \\\n",
      "chapter                                              \n",
      "14        Benjamin Green            Tech Hackathon   \n",
      "22           Lily Nguyen              Fashion Show   \n",
      "45       Scarlett Thomas           Astronomy Night   \n",
      "67           Lucy Carter       Theater Performance   \n",
      "78         Samuel Parker       Theater Performance   \n",
      "88            Henry Reed       Theater Performance   \n",
      "96         Jackson Ramos                 Flash Mob   \n",
      "102        Brooklyn Ross      Educational Workshop   \n",
      "136       Carter Stewart           Astronomy Night   \n",
      "153      Julian Peterson  Fire Dancing Performance   \n",
      "182       Levi Rodriguez            Tech Hackathon   \n",
      "192            Ella Ross    Photography Exhibition   \n",
      "\n",
      "                                             post_entities  n_date  \\\n",
      "chapter                                                              \n",
      "14                                      {Genevieve Burgin}      12   \n",
      "22                             {Evelynn Donohue, Amir Woo}      12   \n",
      "45                           {Rocco Bloom, Milana Harkins}      12   \n",
      "67             {Sol Hutchison, Oakley Emery, Jamal Berlin}      12   \n",
      "78         {Kenna Keeler, Kendra Vanover, Ada Baumgartner}      12   \n",
      "88                                         {Alma Kirkland}      12   \n",
      "96             {Zachary Fajardo, Thor Latta, Osiris Ayala}      12   \n",
      "102                         {Lila Wilkerson, Maci Fennell}      12   \n",
      "136                       {Alec Grainger, Emilia Foresman}      12   \n",
      "153                                         {Jamal Conley}      12   \n",
      "182      {Freya Huff, Dariel Herrick, Joziah Dixon, Mad...      12   \n",
      "192             {Hugo Vanover, Kenna Badger, Selah Kinsey}      12   \n",
      "\n",
      "         n_location  n_entity  n_content  raw_generated_paragraph_idx  \\\n",
      "chapter                                                                 \n",
      "14                7         6         30                           13   \n",
      "22                3         1         17                           22   \n",
      "45               17        15         10                           45   \n",
      "67                7         7         15                           68   \n",
      "78               17        10         15                           79   \n",
      "88                8        15         15                           89   \n",
      "96                2         5          2                           97   \n",
      "102              14         9         10                          103   \n",
      "136              13        13         10                          137   \n",
      "153               4         3         11                          154   \n",
      "182               3        14         30                          185   \n",
      "192              10         1         10                          195   \n",
      "\n",
      "         nb_paragraphs      style  idx_t  idx_s  idx_e  idx_c  \n",
      "chapter                                                        \n",
      "14                   3    romance      3      2      3      1  \n",
      "22                   5    tragedy      3      2      4      1  \n",
      "45                  10   thriller      9      5      5     10  \n",
      "67                   9    fantasy      8      2      8      7  \n",
      "78                   7    fantasy      6      1      1      1  \n",
      "88                   5    fantasy      5      5      2      3  \n",
      "96                   9   thriller      1      9      7      6  \n",
      "102                  4    tragedy      1      2      3      4  \n",
      "136                  1   thriller      1      1      1      1  \n",
      "153                  4  detective      2      3      4      2  \n",
      "182                  3   thriller      1      3      1      1  \n",
      "192                  7    mystery      2      7      3      3  \n"
     ]
    }
   ],
   "source": [
    "# Manual exploration\n",
    "\n",
    "#For the one related with time, always August 24, 2024, with (the following given by 3 different questions):\n",
    "# - Locations: 'One World Trade Center', 'American Museum of Natural History', 'Trinity Church'\n",
    "# - Entities: 'Scarlett Thomas', 'Julian Ross', 'Maya Smith', 'Mila Gonzalez',\n",
    "# - Content: 'Storytelling Festival', 'Carnival', 'Murder Mystery Dinner',\n",
    "\n",
    "# In Chapter 147 (on December 25, 2025): 'Storytelling Festival' <> 'American Museum of Natural History' (with other entities than the one predicted)\n",
    "# In Chapter 120 (on November 13, 2026): 'Murder Mystery Dinner' <> 'One World Trade Center' <> 'Scarlett Thomas' \n",
    "\n",
    "df_gt = benchmark_claude_200.df_book_groundtruth\n",
    "\n",
    "subset1 = df_gt[df_gt['location'] == 'Lincoln Center']\n",
    "print(subset1)\n",
    "\n",
    "subset2 = df_gt[df_gt['content'] == 'Murder Mystery Dinner']\n",
    "print(subset2)\n",
    "\n",
    "subset3 = df_gt[df_gt['entity'] == 'Zoe Rivera']\n",
    "print(subset3)\n",
    "\n",
    "subset4 = df_gt[df_gt['date'] == 'April 09, 2026']\n",
    "print(subset4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
