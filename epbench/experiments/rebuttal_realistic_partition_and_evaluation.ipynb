{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo_filepath = '/filepath/to/gitrepo/episodic-memory-benchmark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default book -- Generation with Claude -- 200 targeted events (finally 196 chapters and 100k tokens)\n",
      "At iteration 0, 33.50% remaining with issues (67/200), for index: [11, 13, 16, 19, 20, 23, 25, 30, 33, 42, 44, 45, 47, 48, 50, 51, 56, 59, 62, 63, 67, 69, 70, 71, 79, 80, 85, 86, 88, 93, 96, 106, 109, 122, 125, 127, 128, 130, 136, 138, 143, 144, 146, 147, 148, 149, 150, 152, 155, 156, 160, 162, 163, 166, 169, 172, 175, 177, 178, 180, 181, 182, 185, 189, 193, 197, 199].\n",
      "At iteration 1, 16.50% remaining with issues (33/200), for index: [11, 13, 16, 42, 44, 56, 59, 67, 79, 80, 93, 96, 106, 122, 127, 128, 130, 136, 143, 144, 146, 147, 150, 156, 160, 162, 163, 166, 169, 172, 175, 182, 193].\n",
      "At iteration 2, 10.50% remaining with issues (21/200), for index: [13, 16, 42, 44, 56, 67, 79, 93, 96, 106, 143, 144, 146, 150, 156, 160, 162, 166, 169, 182, 193].\n",
      "At iteration 3, 7.50% remaining with issues (15/200), for index: [16, 42, 44, 56, 67, 93, 96, 106, 143, 144, 146, 156, 160, 182, 193].\n",
      "At iteration 4, 5.50% remaining with issues (11/200), for index: [16, 42, 44, 56, 67, 93, 146, 156, 160, 182, 193].\n",
      "At iteration 5, 4.50% remaining with issues (9/200), for index: [16, 56, 67, 93, 146, 156, 160, 182, 193].\n",
      "At iteration 6, 3.00% remaining with issues (6/200), for index: [16, 56, 67, 156, 160, 182].\n",
      "At iteration 7, 2.50% remaining with issues (5/200), for index: [16, 56, 67, 156, 160].\n",
      "At iteration 8, 2.00% remaining with issues (4/200), for index: [16, 56, 156, 160].\n",
      "At final iteration 9, 2.00% remaining with issues (4/200), for index: [16, 56, 156, 160].\n",
      "itermax reached but some events still did not pass the verification\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from epbench.src.generation.benchmark_generation_wrapper import BenchmarkGenerationWrapper\n",
    "book_parameters = {'indexing': 'default', 'nb_summaries': 0}\n",
    "data_folder = Path(git_repo_filepath) / 'epbench' / 'data'\n",
    "env_file = Path(git_repo_filepath) / '.env'\n",
    "\n",
    "print(\"Default book -- Generation with Claude -- 200 targeted events (finally 196 chapters and 100k tokens)\")\n",
    "prompt_parameters = {'nb_events': 200, 'name_universe': 'default', 'name_styles': 'default', 'seed': 0, 'distribution_events': {'name': 'geometric', 'param': 0.1}}\n",
    "model_parameters = {'model_name': 'claude-3-5-sonnet-20240620', 'max_new_tokens': 4096, 'itermax': 10}\n",
    "benchmark_claude_200 = BenchmarkGenerationWrapper(prompt_parameters, model_parameters, book_parameters, data_folder, env_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realistic               100\n",
      "Somewhat realistic       52\n",
      "Non-realistic            31\n",
      "Moderately realistic      7\n",
      "Impossible                6\n",
      "Name: count, dtype: int64\n",
      "This event is entirely plausible as it involves a common activity (photography exhibition) at a real location (Port Jefferson) with a reasonable future date. Photography exhibitions and workshops explaining post-processing techniques are regular occurrences in art communities, and the timeframe (2026) is in the near future.\n",
      "This event is moderately realistic because karaoke nights are common social activities, and Chelsea Market is a real venue that could host such events. Performing songs in different languages is also common in karaoke. The specific date in the future and named person make it plausible, though we can't verify if this exact event will occur.\n",
      "While fashion shows in museums do occur occasionally, and the American Museum of Natural History has hosted special events, it's a relatively unusual venue for a fashion show. The specific date in the future and named individual makes it plausible, but museums focused on natural history aren't typical locations for fashion events compared to art museums or conventional fashion venues.\n",
      "This scenario is unlikely because Bethpage Black Course is a prestigious golf course that wouldn't typically allow parkour activities. Golf courses are carefully maintained for golfing and would not permit activities that could damage the turf or disturb golfers. Additionally, parkour typically requires urban structures or obstacles, which wouldn't be present on a golf course.\n",
      "Fire performances are strictly prohibited at the Statue of Liberty as it's a protected national monument with strict security measures. Additionally, visitors are not allowed to perform any kind of shows or demonstrations inside or around the statue due to safety regulations and preservation concerns.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from epbench.src.models.models_wrapper import ModelsWrapper\n",
    "from epbench.src.models.settings_wrapper import SettingsWrapper\n",
    "from epbench.src.io.io import export_list, import_list\n",
    "from epbench.src.io.io import data_folder_experiment_func\n",
    "\n",
    "def rebuttal_realistic_filepath_func(chapter, data_folder, prompt_parameters, model_parameters):\n",
    "    '''\n",
    "    File path of the generated paragraph\n",
    "    '''\n",
    "    prompt_str = f\"chapter{chapter}\"\n",
    "    model_str = f\"model_{model_parameters['model_name']}\"\n",
    "    end_name = f\"{model_str}_{prompt_str}.json\"\n",
    "    data_paragraphs_filepath = Path(data_folder) / data_folder_experiment_func(prompt_parameters) / \"rebuttal_realistic\" / end_name\n",
    "    return data_paragraphs_filepath\n",
    "\n",
    "def event_description_func(l):\n",
    "    return f\"On {l[0]}, {l[2]} did {l[3].lower()} in {l[1]} where they {l[4].lower()}\"\n",
    "\n",
    "def event_realistic_or_not_prompt(chapter, my_benchmark):\n",
    "    event_idx = my_benchmark.debug_mapping_chapter_idx_to_event_idx[chapter]\n",
    "    l = my_benchmark.events[event_idx]\n",
    "    event = event_description_func(l)\n",
    "    return f'Please rate the following event into the one of the category \"Impossible\", \"Non-realistic\" \"Somewhat realistic\", \"Moderately realistic\", \"Realistic\". Here is the event description: \"{event}\". Provide your answer in the following JSON format:\\n{{\"rating\": \"your rating\",\\n\"explanation\": \"Brief explanation of your evaluation\"\\n}}'\n",
    "\n",
    "def generate_realistic_or_not_func(\n",
    "    my_benchmark,\n",
    "    model_parameters = {'model_name': 'claude-3-5-sonnet-20241022', 'max_new_tokens': 4096},\n",
    "    data_folder = Path(git_repo_filepath) / 'epbench/data',\n",
    "    env_file = Path(git_repo_filepath) / '.env'):\n",
    "\n",
    "    # model parameters for generating the judgement\n",
    "    model_name = model_parameters['model_name']\n",
    "    max_new_tokens = model_parameters['max_new_tokens']\n",
    "\n",
    "    # original parameters used for generating the books\n",
    "    prompt_parameters = my_benchmark.prompt_parameters\n",
    "    model_parameters = my_benchmark.model_parameters\n",
    "\n",
    "    config = SettingsWrapper(_env_file = env_file)\n",
    "\n",
    "    generated_judgements = []\n",
    "    for chapter in range(1, my_benchmark.nb_chapters()+1):\n",
    "        user_prompt = event_realistic_or_not_prompt(chapter, my_benchmark)\n",
    "        data_filepath = rebuttal_realistic_filepath_func(chapter, data_folder, prompt_parameters, model_parameters)\n",
    "\n",
    "        if not data_filepath.is_file():\n",
    "            print(\"Generate \" + str(chapter) + \"/\" + str(my_benchmark.nb_chapters()))\n",
    "            # only initialize the model if needed, and only initialize it once \n",
    "            try:\n",
    "                my_model\n",
    "            except NameError:\n",
    "                my_model = ModelsWrapper(model_name, config)\n",
    "            # generate the content\n",
    "            system_prompt = \"You are a content checker AI.\"\n",
    "            out = my_model.generate(user_prompt = user_prompt, system_prompt = system_prompt, max_new_tokens = max_new_tokens)\n",
    "            data_filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "            print(out)\n",
    "            export_list(out, data_filepath)\n",
    "        generated_judgement = import_list(data_filepath)\n",
    "        generated_judgements.append(generated_judgement)\n",
    "\n",
    "    return generated_judgements\n",
    "\n",
    "my_benchmark = benchmark_claude_200\n",
    "res = [json.loads(elem)['rating'] for elem in generate_realistic_or_not_func(my_benchmark)]\n",
    "res0 = [json.loads(elem)['explanation'] for elem in generate_realistic_or_not_func(my_benchmark) if json.loads(elem)['rating'] == 'Realistic']\n",
    "res1 = [json.loads(elem)['explanation'] for elem in generate_realistic_or_not_func(my_benchmark) if json.loads(elem)['rating'] == 'Moderately realistic']\n",
    "res2 = [json.loads(elem)['explanation'] for elem in generate_realistic_or_not_func(my_benchmark) if json.loads(elem)['rating'] == 'Somewhat realistic']\n",
    "res3 = [json.loads(elem)['explanation'] for elem in generate_realistic_or_not_func(my_benchmark) if json.loads(elem)['rating'] == 'Non-realistic']\n",
    "res4 = [json.loads(elem)['explanation'] for elem in generate_realistic_or_not_func(my_benchmark) if json.loads(elem)['rating'] == 'Impossible']\n",
    "\n",
    "print(pd.Series(res).value_counts())\n",
    "# Realistic               100\n",
    "# Moderately realistic      7\n",
    "# Somewhat realistic       52\n",
    "# Non-realistic            31\n",
    "# Impossible                6\n",
    "\n",
    "print(res0[0])\n",
    "# 'This event is entirely plausible as it involves a common activity (photography exhibition) at a real location (Port Jefferson) with a reasonable future date. Photography exhibitions and workshops explaining post-processing techniques are regular occurrences in art communities, and the timeframe (2026) is in the near future.'\n",
    "print(res1[0])\n",
    "# \"This event is moderately realistic because karaoke nights are common social activities, and Chelsea Market is a real venue that could host such events. Performing songs in different languages is also common in karaoke. The specific date in the future and named person make it plausible, though we can't verify if this exact event will occur.\"\n",
    "print(res2[0])\n",
    "# \"While fashion shows in museums do occur occasionally, and the American Museum of Natural History has hosted special events, it's a relatively unusual venue for a fashion show. The specific date in the future and named individual makes it plausible, but museums focused on natural history aren't typical locations for fashion events compared to art museums or conventional fashion venues.\"\n",
    "print(res3[0])\n",
    "# \"This scenario is unlikely because Bethpage Black Course is a prestigious golf course that wouldn't typically allow parkour activities. Golf courses are carefully maintained for golfing and would not permit activities that could damage the turf or disturb golfers. Additionally, parkour typically requires urban structures or obstacles, which wouldn't be present on a golf course.\"\n",
    "print(res4[0])\n",
    "# \"Fire performances are strictly prohibited at the Statue of Liberty as it's a protected national monument with strict security measures. Additionally, visitors are not allowed to perform any kind of shows or demonstrations inside or around the statue due to safety regulations and preservation concerns.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 experiments\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4o-mini-2024-07-18\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4o-2024-08-06\n",
      "Document with 102870 tokens, answer with prompting using with claude-3-haiku-20240307\n",
      "Document with 102870 tokens, answer with prompting using with claude-3-5-sonnet-20240620\n",
      "Document with 102870 tokens, answer with prompting using with llama-3.1-405b-instruct\n",
      "Document with 102870 tokens, answer with prompting using with o1-mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_nb_events</th>\n",
       "      <th>answering_kind</th>\n",
       "      <th>answering_model_name</th>\n",
       "      <th>answering_embedding_chunk</th>\n",
       "      <th>book_model_name</th>\n",
       "      <th>evaluation_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>llama-3.1-405b-instruct</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_nb_events answering_kind        answering_model_name  \\\n",
       "0             200      prompting      gpt-4o-mini-2024-07-18   \n",
       "1             200      prompting           gpt-4o-2024-08-06   \n",
       "2             200      prompting     claude-3-haiku-20240307   \n",
       "3             200      prompting  claude-3-5-sonnet-20240620   \n",
       "4             200      prompting     llama-3.1-405b-instruct   \n",
       "5             200      prompting                     o1-mini   \n",
       "\n",
       "  answering_embedding_chunk             book_model_name  \\\n",
       "0                       n/a  claude-3-5-sonnet-20240620   \n",
       "1                       n/a  claude-3-5-sonnet-20240620   \n",
       "2                       n/a  claude-3-5-sonnet-20240620   \n",
       "3                       n/a  claude-3-5-sonnet-20240620   \n",
       "4                       n/a  claude-3-5-sonnet-20240620   \n",
       "5                       n/a  claude-3-5-sonnet-20240620   \n",
       "\n",
       "                                   evaluation_object  \n",
       "0  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "1  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "2  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "3  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "4  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "5  <epbench.src.evaluation.evaluation_wrapper.Eva...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "from epbench.src.evaluation.precomputed_results import get_precomputed_results\n",
    "\n",
    "experiments = [\n",
    "    # in-context, book with 200 events\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-mini-2024-07-18'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-2024-08-06'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'claude-3-haiku-20240307'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'claude-3-5-sonnet-20240620'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'llama-3.1-405b-instruct'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'o1-mini'},\n",
    "]\n",
    "\n",
    "for i in range(len(experiments)):\n",
    "    if not 'answering_embedding_chunk' in experiments[i]:\n",
    "        experiments[i]['answering_embedding_chunk'] = 'n/a'\n",
    "    experiments[i]['book_model_name'] = 'claude-3-5-sonnet-20240620'\n",
    "\n",
    "print(f\"{len(experiments)} experiments\")\n",
    "\n",
    "all_benchmarks = {'benchmark_claude_default_200': benchmark_claude_200}\n",
    "\n",
    "df = get_precomputed_results(experiments, env_file, data_folder, all_benchmarks)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n"
     ]
    }
   ],
   "source": [
    "# Manually adding the mapping from question to {realistic, non-realistic, empty, both}\n",
    "def chap2real(chapter, my_benchmark):\n",
    "    res = [json.loads(elem)['rating'] for elem in generate_realistic_or_not_func(my_benchmark)]\n",
    "    mapping = {x: r for (r,x) in zip(res, range(1, len(res)+1))}\n",
    "    result = mapping[chapter]\n",
    "    if (result == \"Non-realistic\") or (result == \"Impossible\") or (result == \"Somewhat realistic\"): \n",
    "        return \"non-realistic\"\n",
    "    else:\n",
    "        return \"realistic\"\n",
    "\n",
    "my_benchmark = benchmark_claude_200\n",
    "series_chapters = df.iloc[0]['evaluation_object'].df_generated_evaluations['correct_answer_chapters']\n",
    "l=[]\n",
    "\n",
    "for i in range(len(series_chapters)):\n",
    "    print(i)\n",
    "    result = [chap2real(x, my_benchmark) for x in series_chapters.iloc[i]]\n",
    "    has_real = 0\n",
    "    has_nonreal = 0\n",
    "    if \"non-realistic\" in result:\n",
    "        has_nonreal = 1\n",
    "    if \"realistic\" in result:\n",
    "        has_real = 1\n",
    "    \n",
    "    if (has_real == 0) and (has_nonreal == 0):\n",
    "        r = \"empty\"\n",
    "    elif (has_real == 1) and (has_nonreal == 0):\n",
    "        r = \"realistic\"\n",
    "    elif (has_real == 0) and (has_nonreal == 1):\n",
    "        r = \"non-realistic\"\n",
    "    else: \n",
    "        r = \"both\"\n",
    "    l.append(r)\n",
    "\n",
    "for i in range(len(df)):\n",
    "  df.iloc[i]['evaluation_object'].df_generated_evaluations['realism'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins_items_correct_answer</th>\n",
       "      <th>realism</th>\n",
       "      <th>count</th>\n",
       "      <th>(prompting, gpt-4o-mini-2024-07-18, n/a)</th>\n",
       "      <th>(prompting, gpt-4o-2024-08-06, n/a)</th>\n",
       "      <th>(prompting, claude-3-haiku-20240307, n/a)</th>\n",
       "      <th>(prompting, claude-3-5-sonnet-20240620, n/a)</th>\n",
       "      <th>(prompting, llama-3.1-405b-instruct, n/a)</th>\n",
       "      <th>(prompting, o1-mini, n/a)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>empty</td>\n",
       "      <td>150</td>\n",
       "      <td>0.51±0.50</td>\n",
       "      <td>0.84±0.37</td>\n",
       "      <td>0.84±0.37</td>\n",
       "      <td>0.92±0.27</td>\n",
       "      <td>0.80±0.40</td>\n",
       "      <td>0.97±0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>non-realistic</td>\n",
       "      <td>57</td>\n",
       "      <td>0.55±0.46</td>\n",
       "      <td>0.91±0.27</td>\n",
       "      <td>0.51±0.49</td>\n",
       "      <td>0.29±0.45</td>\n",
       "      <td>0.50±0.48</td>\n",
       "      <td>0.02±0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>realistic</td>\n",
       "      <td>93</td>\n",
       "      <td>0.53±0.46</td>\n",
       "      <td>0.74±0.43</td>\n",
       "      <td>0.32±0.47</td>\n",
       "      <td>0.39±0.49</td>\n",
       "      <td>0.49±0.47</td>\n",
       "      <td>0.06±0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>both</td>\n",
       "      <td>33</td>\n",
       "      <td>0.51±0.37</td>\n",
       "      <td>0.64±0.32</td>\n",
       "      <td>0.38±0.30</td>\n",
       "      <td>0.38±0.32</td>\n",
       "      <td>0.37±0.33</td>\n",
       "      <td>0.16±0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>non-realistic</td>\n",
       "      <td>24</td>\n",
       "      <td>0.52±0.35</td>\n",
       "      <td>0.61±0.24</td>\n",
       "      <td>0.48±0.27</td>\n",
       "      <td>0.29±0.29</td>\n",
       "      <td>0.48±0.29</td>\n",
       "      <td>0.15±0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>realistic</td>\n",
       "      <td>33</td>\n",
       "      <td>0.32±0.34</td>\n",
       "      <td>0.55±0.35</td>\n",
       "      <td>0.30±0.31</td>\n",
       "      <td>0.35±0.36</td>\n",
       "      <td>0.31±0.36</td>\n",
       "      <td>0.05±0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3-5</td>\n",
       "      <td>both</td>\n",
       "      <td>61</td>\n",
       "      <td>0.46±0.29</td>\n",
       "      <td>0.54±0.19</td>\n",
       "      <td>0.35±0.28</td>\n",
       "      <td>0.31±0.25</td>\n",
       "      <td>0.36±0.23</td>\n",
       "      <td>0.10±0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3-5</td>\n",
       "      <td>non-realistic</td>\n",
       "      <td>13</td>\n",
       "      <td>0.42±0.17</td>\n",
       "      <td>0.68±0.20</td>\n",
       "      <td>0.47±0.26</td>\n",
       "      <td>0.36±0.23</td>\n",
       "      <td>0.52±0.24</td>\n",
       "      <td>0.17±0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3-5</td>\n",
       "      <td>realistic</td>\n",
       "      <td>24</td>\n",
       "      <td>0.55±0.27</td>\n",
       "      <td>0.61±0.24</td>\n",
       "      <td>0.36±0.28</td>\n",
       "      <td>0.30±0.28</td>\n",
       "      <td>0.45±0.28</td>\n",
       "      <td>0.14±0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6+</td>\n",
       "      <td>both</td>\n",
       "      <td>57</td>\n",
       "      <td>0.51±0.17</td>\n",
       "      <td>0.54±0.14</td>\n",
       "      <td>0.37±0.19</td>\n",
       "      <td>0.40±0.20</td>\n",
       "      <td>0.45±0.21</td>\n",
       "      <td>0.24±0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6+</td>\n",
       "      <td>non-realistic</td>\n",
       "      <td>3</td>\n",
       "      <td>0.48±0.09</td>\n",
       "      <td>0.43±0.04</td>\n",
       "      <td>0.48±0.08</td>\n",
       "      <td>0.53±0.07</td>\n",
       "      <td>0.38±0.07</td>\n",
       "      <td>0.28±0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bins_items_correct_answer        realism  count  \\\n",
       "1                          0          empty    150   \n",
       "6                          1  non-realistic     57   \n",
       "7                          1      realistic     93   \n",
       "8                          2           both     33   \n",
       "10                         2  non-realistic     24   \n",
       "11                         2      realistic     33   \n",
       "12                       3-5           both     61   \n",
       "14                       3-5  non-realistic     13   \n",
       "15                       3-5      realistic     24   \n",
       "16                        6+           both     57   \n",
       "18                        6+  non-realistic      3   \n",
       "\n",
       "   (prompting, gpt-4o-mini-2024-07-18, n/a)  \\\n",
       "1                                 0.51±0.50   \n",
       "6                                 0.55±0.46   \n",
       "7                                 0.53±0.46   \n",
       "8                                 0.51±0.37   \n",
       "10                                0.52±0.35   \n",
       "11                                0.32±0.34   \n",
       "12                                0.46±0.29   \n",
       "14                                0.42±0.17   \n",
       "15                                0.55±0.27   \n",
       "16                                0.51±0.17   \n",
       "18                                0.48±0.09   \n",
       "\n",
       "   (prompting, gpt-4o-2024-08-06, n/a)  \\\n",
       "1                            0.84±0.37   \n",
       "6                            0.91±0.27   \n",
       "7                            0.74±0.43   \n",
       "8                            0.64±0.32   \n",
       "10                           0.61±0.24   \n",
       "11                           0.55±0.35   \n",
       "12                           0.54±0.19   \n",
       "14                           0.68±0.20   \n",
       "15                           0.61±0.24   \n",
       "16                           0.54±0.14   \n",
       "18                           0.43±0.04   \n",
       "\n",
       "   (prompting, claude-3-haiku-20240307, n/a)  \\\n",
       "1                                  0.84±0.37   \n",
       "6                                  0.51±0.49   \n",
       "7                                  0.32±0.47   \n",
       "8                                  0.38±0.30   \n",
       "10                                 0.48±0.27   \n",
       "11                                 0.30±0.31   \n",
       "12                                 0.35±0.28   \n",
       "14                                 0.47±0.26   \n",
       "15                                 0.36±0.28   \n",
       "16                                 0.37±0.19   \n",
       "18                                 0.48±0.08   \n",
       "\n",
       "   (prompting, claude-3-5-sonnet-20240620, n/a)  \\\n",
       "1                                     0.92±0.27   \n",
       "6                                     0.29±0.45   \n",
       "7                                     0.39±0.49   \n",
       "8                                     0.38±0.32   \n",
       "10                                    0.29±0.29   \n",
       "11                                    0.35±0.36   \n",
       "12                                    0.31±0.25   \n",
       "14                                    0.36±0.23   \n",
       "15                                    0.30±0.28   \n",
       "16                                    0.40±0.20   \n",
       "18                                    0.53±0.07   \n",
       "\n",
       "   (prompting, llama-3.1-405b-instruct, n/a) (prompting, o1-mini, n/a)  \n",
       "1                                  0.80±0.40                 0.97±0.16  \n",
       "6                                  0.50±0.48                 0.02±0.09  \n",
       "7                                  0.49±0.47                 0.06±0.22  \n",
       "8                                  0.37±0.33                 0.16±0.28  \n",
       "10                                 0.48±0.29                 0.15±0.25  \n",
       "11                                 0.31±0.36                 0.05±0.16  \n",
       "12                                 0.36±0.23                 0.10±0.16  \n",
       "14                                 0.52±0.24                 0.17±0.21  \n",
       "15                                 0.45±0.28                 0.14±0.24  \n",
       "16                                 0.45±0.21                 0.24±0.20  \n",
       "18                                 0.38±0.07                 0.28±0.07  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epbench.src.results.average_groups import extract_groups\n",
    "nb_events = 200 # select the book of interest (either 20 or 200)\n",
    "relative_to = ['get', 'bins_items_correct_answer', 'realism'] # select the grouped elements as a list among:\n",
    "#relative_to = ['get', 'realism'] # select the grouped elements as a list among:\n",
    "# 'get': type of question, among 'all' (simple recall questions), 'latest' (latest state questions), or 'chronological' (chronological questions)\n",
    "# 'bins_items_correct_answer': number of events for this question, binned into {0}, {1}, {2}, {3,4,5}, {6+} chapters\n",
    "# 'cue': type of cue for this question, e.g. (*,*,*,c)\n",
    "# 'retrieval_type': type of trace for this question, e.g. 'Spaces'\n",
    "df_results = extract_groups(df, nb_events, relative_to) # group the results according to `relative_to`\n",
    "\n",
    "# Further filtering, e.g. for selecting only the simple recall questions:\n",
    "df_results = df_results[df_results['get'] == 'all'].drop('get', axis = 1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ablation realistic vs non-realistic subsets of questions: one-sided Mann-Whitney U tests between subset of answers realistic vs non-realistic.\n",
      "For model gpt-4o-mini-2024-07-18, we obtain a p-value of 0.329\n",
      "For model gpt-4o-2024-08-06, we obtain a p-value of 0.0078\n",
      "For model claude-3-haiku-20240307, we obtain a p-value of 0.0002\n",
      "For model claude-3-5-sonnet-20240620, we obtain a p-value of 0.941\n",
      "For model llama-3.1-405b-instruct, we obtain a p-value of 0.7888\n",
      "For model o1-mini, we obtain a p-value of 0.4185\n"
     ]
    }
   ],
   "source": [
    "# Compute the statistical tests\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df_sliced = df[(df['book_nb_events'] == nb_events) & (df['book_model_name'] == 'claude-3-5-sonnet-20240620')]\n",
    "\n",
    "print(\"Ablation realistic vs non-realistic subsets of questions: one-sided Mann-Whitney U tests between subset of answers realistic vs non-realistic.\")\n",
    "\n",
    "for i in range(len(df_sliced)):\n",
    "    df_res_0 = df_sliced.iloc[i]['evaluation_object'].df_generated_evaluations\n",
    "    group1 = df_res_0[df_res_0['realism'] == 'realistic']\n",
    "    group2 = df_res_0[df_res_0['realism'] == 'non-realistic']\n",
    "    a = np.array(group1['f1_score_lenient'].tolist())\n",
    "    b = np.array(group2['f1_score_lenient'].tolist())\n",
    "    statistic, p_value = stats.mannwhitneyu(b, a, alternative='greater')\n",
    "    print(f\"For model {df_sliced.iloc[i]['answering_model_name']}, we obtain a p-value of {round(p_value,4)}\")\n",
    "\n",
    "#Ablation realistic vs non-realistic subsets of questions: one-sided Mann-Whitney U tests between subset of answers realistic vs non-realistic.\n",
    "#For model gpt-4o-mini-2024-07-18, we obtain a p-value of 0.329\n",
    "#For model gpt-4o-2024-08-06, we obtain a p-value of 0.0078\n",
    "#For model claude-3-haiku-20240307, we obtain a p-value of 0.0002\n",
    "#For model claude-3-5-sonnet-20240620, we obtain a p-value of 0.941\n",
    "#For model llama-3.1-405b-instruct, we obtain a p-value of 0.7888\n",
    "#For model o1-mini, we obtain a p-value of 0.4185"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
