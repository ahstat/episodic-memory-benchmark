{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo_filepath = '/filepath/to/gitrepo/episodic-memory-benchmark'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0, 20.00% remaining with issues (4/20), for index: [11, 13, 16, 19].\n",
      "At iteration 1, 15.00% remaining with issues (3/20), for index: [11, 13, 16].\n",
      "At iteration 2, 10.00% remaining with issues (2/20), for index: [13, 16].\n",
      "At iteration 3, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 4, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 5, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 6, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 7, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At iteration 8, 5.00% remaining with issues (1/20), for index: [16].\n",
      "At final iteration 9, 5.00% remaining with issues (1/20), for index: [16].\n",
      "itermax reached but some events still did not pass the verification\n",
      "At iteration 0, 33.50% remaining with issues (67/200), for index: [11, 13, 16, 19, 20, 23, 25, 30, 33, 42, 44, 45, 47, 48, 50, 51, 56, 59, 62, 63, 67, 69, 70, 71, 79, 80, 85, 86, 88, 93, 96, 106, 109, 122, 125, 127, 128, 130, 136, 138, 143, 144, 146, 147, 148, 149, 150, 152, 155, 156, 160, 162, 163, 166, 169, 172, 175, 177, 178, 180, 181, 182, 185, 189, 193, 197, 199].\n",
      "At iteration 1, 16.50% remaining with issues (33/200), for index: [11, 13, 16, 42, 44, 56, 59, 67, 79, 80, 93, 96, 106, 122, 127, 128, 130, 136, 143, 144, 146, 147, 150, 156, 160, 162, 163, 166, 169, 172, 175, 182, 193].\n",
      "At iteration 2, 10.50% remaining with issues (21/200), for index: [13, 16, 42, 44, 56, 67, 79, 93, 96, 106, 143, 144, 146, 150, 156, 160, 162, 166, 169, 182, 193].\n",
      "At iteration 3, 7.50% remaining with issues (15/200), for index: [16, 42, 44, 56, 67, 93, 96, 106, 143, 144, 146, 156, 160, 182, 193].\n",
      "At iteration 4, 5.50% remaining with issues (11/200), for index: [16, 42, 44, 56, 67, 93, 146, 156, 160, 182, 193].\n",
      "At iteration 5, 4.50% remaining with issues (9/200), for index: [16, 56, 67, 93, 146, 156, 160, 182, 193].\n",
      "At iteration 6, 3.00% remaining with issues (6/200), for index: [16, 56, 67, 156, 160, 182].\n",
      "At iteration 7, 2.50% remaining with issues (5/200), for index: [16, 56, 67, 156, 160].\n",
      "At iteration 8, 2.00% remaining with issues (4/200), for index: [16, 56, 156, 160].\n",
      "At final iteration 9, 2.00% remaining with issues (4/200), for index: [16, 56, 156, 160].\n",
      "itermax reached but some events still did not pass the verification\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from epbench.src.generation.benchmark_generation_wrapper import BenchmarkGenerationWrapper\n",
    "book_parameters = {'indexing': 'default', 'nb_summaries': 0}\n",
    "data_folder = Path(git_repo_filepath) / 'epbench' / 'data'\n",
    "env_file = Path(git_repo_filepath) / '.env'\n",
    "\n",
    "# Generation with Claude -- 20 events\n",
    "prompt_parameters = {'nb_events': 20, 'name_universe': 'default', 'name_styles': 'default', 'seed': 0, 'distribution_events': {'name': 'geometric', 'param': 0.1}}\n",
    "model_parameters = {'model_name': 'claude-3-5-sonnet-20240620', 'max_new_tokens': 4096, 'itermax': 10}\n",
    "benchmark_claude_20 = BenchmarkGenerationWrapper(prompt_parameters, model_parameters, book_parameters, data_folder, env_file)\n",
    "\n",
    "# Generation with Claude -- 200 events\n",
    "prompt_parameters = {'nb_events': 200, 'name_universe': 'default', 'name_styles': 'default', 'seed': 0, 'distribution_events': {'name': 'geometric', 'param': 0.1}}\n",
    "model_parameters = {'model_name': 'claude-3-5-sonnet-20240620', 'max_new_tokens': 4096, 'itermax': 10}\n",
    "benchmark_claude_200 = BenchmarkGenerationWrapper(prompt_parameters, model_parameters, book_parameters, data_folder, env_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional experiments (in-context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with 10397 tokens, answer with prompting using with claude-sonnet-4-20250514\n",
      "Document with 10397 tokens, answer with prompting using with gemini-2.5-flash\n",
      "Document with 10397 tokens, answer with prompting using with gemini-2.5-pro\n",
      "Document with 10397 tokens, answer with prompting using with gpt-5\n",
      "Document with 10397 tokens, answer with prompting using with gpt-5-mini\n",
      "Document with 10397 tokens, answer with prompting using with gpt-4.1-nano\n",
      "Document with 10397 tokens, answer with prompting using with grok-4-fast-non-reasoning\n",
      "Document with 10397 tokens, answer with prompting using with grok-4-fast-reasoning\n",
      "Document with 102870 tokens, answer with prompting using with claude-sonnet-4-20250514\n",
      "Document with 102870 tokens, answer with prompting using with gemini-2.5-flash\n",
      "Document with 102870 tokens, answer with prompting using with gemini-2.5-pro\n",
      "Document with 102870 tokens, answer with prompting using with gpt-5\n",
      "Document with 102870 tokens, answer with prompting using with gpt-5-mini\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4.1-nano\n",
      "Document with 102870 tokens, answer with prompting using with grok-4-fast-non-reasoning\n",
      "Document with 102870 tokens, answer with prompting using with grok-4-fast-reasoning\n",
      "Document with 10397 tokens, answer with prompting using with gpt-5-nano\n",
      "Experiment ended (prompting)\n"
     ]
    }
   ],
   "source": [
    "# Done already:\n",
    "# - Iteration 1: 'gpt-4o-mini-2024-07-18', 'gpt-4o-2024-08-06', 'claude-3-haiku-20240307', 'claude-3-5-sonnet-20240620', 'o1-mini', 'llama-3.1-405b-instruct'\n",
    "# - Iteration 2: 'o1','o3-mini', 'gemini-2.0-flash-001', 'gemini-2.0-flash-thinking-exp-01-21', 'gemini-2.0-pro-exp-02-05', 'deepseek-chat', 'deepseek-reasoner'\n",
    "# - This iteration: 'claude-sonnet-4-20250514', 'gemini-2.5-flash', 'gemini-2.5-pro', 'gpt-5', 'gpt-5-mini', 'gpt-4.1-nano', 'grok-4-fast-non-reasoning', 'grok-4-fast-reasoning'\n",
    "\n",
    "from epbench.src.evaluation.evaluation_wrapper import EvaluationWrapper\n",
    "\n",
    "for my_benchmark in [benchmark_claude_20, benchmark_claude_200]:\n",
    "    for model_name in ['claude-sonnet-4-20250514', 'gemini-2.5-flash', 'gemini-2.5-pro', 'gpt-5', 'gpt-5-mini', 'gpt-4.1-nano', 'grok-4-fast-non-reasoning', 'grok-4-fast-reasoning']:\n",
    "        answering_parameters = {'kind': 'prompting', 'model_name': model_name, 'max_new_tokens': 4096, 'sleeping_time': 1, 'policy': 'remove_duplicates'}\n",
    "        print(f\"Document with {my_benchmark.nb_tokens()} tokens, answer with prompting using with {model_name}\")\n",
    "        my_evaluation = EvaluationWrapper(my_benchmark, answering_parameters, data_folder, env_file)\n",
    "\n",
    "for my_benchmark in [benchmark_claude_20]:\n",
    "    for model_name in ['gpt-5-nano']:\n",
    "        answering_parameters = {'kind': 'prompting', 'model_name': model_name, 'max_new_tokens': 4096, 'sleeping_time': 1, 'policy': 'remove_duplicates'}\n",
    "        print(f\"Document with {my_benchmark.nb_tokens()} tokens, answer with prompting using with {model_name}\")\n",
    "        my_evaluation = EvaluationWrapper(my_benchmark, answering_parameters, data_folder, env_file)\n",
    "\n",
    "print(\"Experiment ended (prompting)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading experiments (in-context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 experiments\n",
      "Document with 10397 tokens, answer with prompting using with gpt-4o-mini-2024-07-18\n",
      "Document with 10397 tokens, answer with prompting using with gpt-4o-2024-08-06\n",
      "Document with 10397 tokens, answer with prompting using with gpt-4.1-nano\n",
      "Document with 10397 tokens, answer with prompting using with gpt-5-nano\n",
      "Document with 10397 tokens, answer with prompting using with gpt-5-mini\n",
      "Document with 10397 tokens, answer with prompting using with gpt-5\n",
      "Document with 10397 tokens, answer with prompting using with claude-3-haiku-20240307\n",
      "Document with 10397 tokens, answer with prompting using with claude-3-5-sonnet-20240620\n",
      "Document with 10397 tokens, answer with prompting using with claude-sonnet-4-20250514\n",
      "Document with 10397 tokens, answer with prompting using with o1-mini\n",
      "Document with 10397 tokens, answer with prompting using with o1\n",
      "Document with 10397 tokens, answer with prompting using with o3-mini\n",
      "Document with 10397 tokens, answer with prompting using with llama-3.1-405b-instruct\n",
      "Document with 10397 tokens, answer with prompting using with gemini-2.0-flash-001\n",
      "Document with 10397 tokens, answer with prompting using with gemini-2.0-flash-thinking-exp-01-21\n",
      "Document with 10397 tokens, answer with prompting using with gemini-2.5-flash\n",
      "Document with 10397 tokens, answer with prompting using with gemini-2.0-pro-exp-02-05\n",
      "Document with 10397 tokens, answer with prompting using with gemini-2.5-pro\n",
      "Document with 10397 tokens, answer with prompting using with deepseek-chat\n",
      "Document with 10397 tokens, answer with prompting using with deepseek-reasoner\n",
      "Document with 10397 tokens, answer with prompting using with grok-4-fast-non-reasoning\n",
      "Document with 10397 tokens, answer with prompting using with grok-4-fast-reasoning\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4o-mini-2024-07-18\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4o-2024-08-06\n",
      "Document with 102870 tokens, answer with prompting using with gpt-4.1-nano\n",
      "Document with 102870 tokens, answer with prompting using with gpt-5-mini\n",
      "Document with 102870 tokens, answer with prompting using with gpt-5\n",
      "Document with 102870 tokens, answer with prompting using with claude-3-haiku-20240307\n",
      "Document with 102870 tokens, answer with prompting using with claude-3-5-sonnet-20240620\n",
      "Document with 102870 tokens, answer with prompting using with claude-sonnet-4-20250514\n",
      "Document with 102870 tokens, answer with prompting using with o1-mini\n",
      "Document with 102870 tokens, answer with prompting using with o1\n",
      "Document with 102870 tokens, answer with prompting using with o3-mini\n",
      "Document with 102870 tokens, answer with prompting using with llama-3.1-405b-instruct\n",
      "Document with 102870 tokens, answer with prompting using with gemini-2.0-flash-001\n",
      "Document with 102870 tokens, answer with prompting using with gemini-2.0-flash-thinking-exp-01-21\n",
      "Document with 102870 tokens, answer with prompting using with gemini-2.5-flash\n",
      "Document with 102870 tokens, answer with prompting using with gemini-2.0-pro-exp-02-05\n",
      "Document with 102870 tokens, answer with prompting using with gemini-2.5-pro\n",
      "Document with 102870 tokens, answer with prompting using with deepseek-chat\n",
      "Document with 102870 tokens, answer with prompting using with deepseek-reasoner\n",
      "Document with 102870 tokens, answer with prompting using with grok-4-fast-non-reasoning\n",
      "Document with 102870 tokens, answer with prompting using with grok-4-fast-reasoning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_nb_events</th>\n",
       "      <th>answering_kind</th>\n",
       "      <th>answering_model_name</th>\n",
       "      <th>answering_embedding_chunk</th>\n",
       "      <th>book_model_name</th>\n",
       "      <th>evaluation_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-5-nano</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-5-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-5</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-sonnet-4-20250514</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o1</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o3-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>llama-3.1-405b-instruct</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.0-flash-001</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.0-flash-thinking-exp-01-21</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.0-pro-exp-02-05</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>deepseek-reasoner</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>grok-4-fast-non-reasoning</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>grok-4-fast-reasoning</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-5-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gpt-5</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>claude-sonnet-4-20250514</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o1-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o1</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>o3-mini</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>llama-3.1-405b-instruct</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.0-flash-001</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.0-flash-thinking-exp-01-21</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.0-pro-exp-02-05</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>deepseek-reasoner</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>grok-4-fast-non-reasoning</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>grok-4-fast-reasoning</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_nb_events answering_kind                 answering_model_name  \\\n",
       "0               20      prompting               gpt-4o-mini-2024-07-18   \n",
       "1               20      prompting                    gpt-4o-2024-08-06   \n",
       "2               20      prompting                         gpt-4.1-nano   \n",
       "3               20      prompting                           gpt-5-nano   \n",
       "4               20      prompting                           gpt-5-mini   \n",
       "5               20      prompting                                gpt-5   \n",
       "6               20      prompting              claude-3-haiku-20240307   \n",
       "7               20      prompting           claude-3-5-sonnet-20240620   \n",
       "8               20      prompting             claude-sonnet-4-20250514   \n",
       "9               20      prompting                              o1-mini   \n",
       "10              20      prompting                                   o1   \n",
       "11              20      prompting                              o3-mini   \n",
       "12              20      prompting              llama-3.1-405b-instruct   \n",
       "13              20      prompting                 gemini-2.0-flash-001   \n",
       "14              20      prompting  gemini-2.0-flash-thinking-exp-01-21   \n",
       "15              20      prompting                     gemini-2.5-flash   \n",
       "16              20      prompting             gemini-2.0-pro-exp-02-05   \n",
       "17              20      prompting                       gemini-2.5-pro   \n",
       "18              20      prompting                        deepseek-chat   \n",
       "19              20      prompting                    deepseek-reasoner   \n",
       "20              20      prompting            grok-4-fast-non-reasoning   \n",
       "21              20      prompting                grok-4-fast-reasoning   \n",
       "22             200      prompting               gpt-4o-mini-2024-07-18   \n",
       "23             200      prompting                    gpt-4o-2024-08-06   \n",
       "24             200      prompting                         gpt-4.1-nano   \n",
       "25             200      prompting                           gpt-5-mini   \n",
       "26             200      prompting                                gpt-5   \n",
       "27             200      prompting              claude-3-haiku-20240307   \n",
       "28             200      prompting           claude-3-5-sonnet-20240620   \n",
       "29             200      prompting             claude-sonnet-4-20250514   \n",
       "30             200      prompting                              o1-mini   \n",
       "31             200      prompting                                   o1   \n",
       "32             200      prompting                              o3-mini   \n",
       "33             200      prompting              llama-3.1-405b-instruct   \n",
       "34             200      prompting                 gemini-2.0-flash-001   \n",
       "35             200      prompting  gemini-2.0-flash-thinking-exp-01-21   \n",
       "36             200      prompting                     gemini-2.5-flash   \n",
       "37             200      prompting             gemini-2.0-pro-exp-02-05   \n",
       "38             200      prompting                       gemini-2.5-pro   \n",
       "39             200      prompting                        deepseek-chat   \n",
       "40             200      prompting                    deepseek-reasoner   \n",
       "41             200      prompting            grok-4-fast-non-reasoning   \n",
       "42             200      prompting                grok-4-fast-reasoning   \n",
       "\n",
       "   answering_embedding_chunk             book_model_name  \\\n",
       "0                        n/a  claude-3-5-sonnet-20240620   \n",
       "1                        n/a  claude-3-5-sonnet-20240620   \n",
       "2                        n/a  claude-3-5-sonnet-20240620   \n",
       "3                        n/a  claude-3-5-sonnet-20240620   \n",
       "4                        n/a  claude-3-5-sonnet-20240620   \n",
       "5                        n/a  claude-3-5-sonnet-20240620   \n",
       "6                        n/a  claude-3-5-sonnet-20240620   \n",
       "7                        n/a  claude-3-5-sonnet-20240620   \n",
       "8                        n/a  claude-3-5-sonnet-20240620   \n",
       "9                        n/a  claude-3-5-sonnet-20240620   \n",
       "10                       n/a  claude-3-5-sonnet-20240620   \n",
       "11                       n/a  claude-3-5-sonnet-20240620   \n",
       "12                       n/a  claude-3-5-sonnet-20240620   \n",
       "13                       n/a  claude-3-5-sonnet-20240620   \n",
       "14                       n/a  claude-3-5-sonnet-20240620   \n",
       "15                       n/a  claude-3-5-sonnet-20240620   \n",
       "16                       n/a  claude-3-5-sonnet-20240620   \n",
       "17                       n/a  claude-3-5-sonnet-20240620   \n",
       "18                       n/a  claude-3-5-sonnet-20240620   \n",
       "19                       n/a  claude-3-5-sonnet-20240620   \n",
       "20                       n/a  claude-3-5-sonnet-20240620   \n",
       "21                       n/a  claude-3-5-sonnet-20240620   \n",
       "22                       n/a  claude-3-5-sonnet-20240620   \n",
       "23                       n/a  claude-3-5-sonnet-20240620   \n",
       "24                       n/a  claude-3-5-sonnet-20240620   \n",
       "25                       n/a  claude-3-5-sonnet-20240620   \n",
       "26                       n/a  claude-3-5-sonnet-20240620   \n",
       "27                       n/a  claude-3-5-sonnet-20240620   \n",
       "28                       n/a  claude-3-5-sonnet-20240620   \n",
       "29                       n/a  claude-3-5-sonnet-20240620   \n",
       "30                       n/a  claude-3-5-sonnet-20240620   \n",
       "31                       n/a  claude-3-5-sonnet-20240620   \n",
       "32                       n/a  claude-3-5-sonnet-20240620   \n",
       "33                       n/a  claude-3-5-sonnet-20240620   \n",
       "34                       n/a  claude-3-5-sonnet-20240620   \n",
       "35                       n/a  claude-3-5-sonnet-20240620   \n",
       "36                       n/a  claude-3-5-sonnet-20240620   \n",
       "37                       n/a  claude-3-5-sonnet-20240620   \n",
       "38                       n/a  claude-3-5-sonnet-20240620   \n",
       "39                       n/a  claude-3-5-sonnet-20240620   \n",
       "40                       n/a  claude-3-5-sonnet-20240620   \n",
       "41                       n/a  claude-3-5-sonnet-20240620   \n",
       "42                       n/a  claude-3-5-sonnet-20240620   \n",
       "\n",
       "                                    evaluation_object  \n",
       "0   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "1   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "2   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "3   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "4   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "5   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "6   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "7   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "8   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "9   <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "10  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "11  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "12  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "13  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "14  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "15  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "16  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "17  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "18  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "19  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "20  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "21  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "22  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "23  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "24  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "25  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "26  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "27  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "28  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "29  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "30  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "31  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "32  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "33  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "34  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "35  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "36  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "37  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "38  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "39  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "40  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "41  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "42  <epbench.src.evaluation.evaluation_wrapper.Eva...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "from epbench.src.evaluation.precomputed_results import get_precomputed_results\n",
    "\n",
    "experiments = [\n",
    "    # in-context, book with 20 events\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-mini-2024-07-18'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-2024-08-06'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gpt-4.1-nano'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gpt-5-nano'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gpt-5-mini'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gpt-5'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'claude-3-haiku-20240307'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'claude-3-5-sonnet-20240620'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'claude-sonnet-4-20250514'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'o1-mini'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'o1'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'o3-mini'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'llama-3.1-405b-instruct'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.0-flash-001'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.0-flash-thinking-exp-01-21'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.5-flash'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.0-pro-exp-02-05'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.5-pro'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'deepseek-chat'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'deepseek-reasoner'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'grok-4-fast-non-reasoning'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'grok-4-fast-reasoning'},\n",
    "    # in-context, book with 200 events\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-mini-2024-07-18'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-4o-2024-08-06'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-4.1-nano'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-5-mini'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gpt-5'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'claude-3-haiku-20240307'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'claude-3-5-sonnet-20240620'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'claude-sonnet-4-20250514'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'o1-mini'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'o1'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'o3-mini'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'llama-3.1-405b-instruct'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.0-flash-001'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.0-flash-thinking-exp-01-21'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.5-flash'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.0-pro-exp-02-05'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'gemini-2.5-pro'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'deepseek-chat'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'deepseek-reasoner'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'grok-4-fast-non-reasoning'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'grok-4-fast-reasoning'}\n",
    "]\n",
    "\n",
    "for i in range(len(experiments)):\n",
    "    if not 'answering_embedding_chunk' in experiments[i]:\n",
    "        experiments[i]['answering_embedding_chunk'] = 'n/a'\n",
    "    experiments[i]['book_model_name'] = 'claude-3-5-sonnet-20240620'\n",
    "\n",
    "print(f\"{len(experiments)} experiments\")\n",
    "\n",
    "all_benchmarks = {'benchmark_claude_default_20': benchmark_claude_20,\n",
    "                  'benchmark_claude_default_200': benchmark_claude_200}\n",
    "\n",
    "df = get_precomputed_results(experiments, env_file, data_folder, all_benchmarks)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of table with comparison of the different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins_items_correct_answer</th>\n",
       "      <th>count</th>\n",
       "      <th>(prompting, gpt-4o-mini-2024-07-18, n/a)</th>\n",
       "      <th>(prompting, gpt-4o-2024-08-06, n/a)</th>\n",
       "      <th>(prompting, gpt-4.1-nano, n/a)</th>\n",
       "      <th>(prompting, gpt-5-mini, n/a)</th>\n",
       "      <th>(prompting, gpt-5, n/a)</th>\n",
       "      <th>(prompting, claude-3-haiku-20240307, n/a)</th>\n",
       "      <th>(prompting, claude-3-5-sonnet-20240620, n/a)</th>\n",
       "      <th>(prompting, claude-sonnet-4-20250514, n/a)</th>\n",
       "      <th>...</th>\n",
       "      <th>(prompting, llama-3.1-405b-instruct, n/a)</th>\n",
       "      <th>(prompting, gemini-2.0-flash-001, n/a)</th>\n",
       "      <th>(prompting, gemini-2.0-flash-thinking-exp-01-21, n/a)</th>\n",
       "      <th>(prompting, gemini-2.5-flash, n/a)</th>\n",
       "      <th>(prompting, gemini-2.0-pro-exp-02-05, n/a)</th>\n",
       "      <th>(prompting, gemini-2.5-pro, n/a)</th>\n",
       "      <th>(prompting, deepseek-chat, n/a)</th>\n",
       "      <th>(prompting, deepseek-reasoner, n/a)</th>\n",
       "      <th>(prompting, grok-4-fast-non-reasoning, n/a)</th>\n",
       "      <th>(prompting, grok-4-fast-reasoning, n/a)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0.51±0.50</td>\n",
       "      <td>0.84±0.37</td>\n",
       "      <td>0.42±0.50</td>\n",
       "      <td>0.95±0.21</td>\n",
       "      <td>0.95±0.21</td>\n",
       "      <td>0.84±0.37</td>\n",
       "      <td>0.92±0.27</td>\n",
       "      <td>0.90±0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80±0.40</td>\n",
       "      <td>0.87±0.33</td>\n",
       "      <td>0.91±0.29</td>\n",
       "      <td>0.98±0.14</td>\n",
       "      <td>0.85±0.36</td>\n",
       "      <td>0.99±0.08</td>\n",
       "      <td>0.79±0.41</td>\n",
       "      <td>0.92±0.27</td>\n",
       "      <td>0.73±0.45</td>\n",
       "      <td>0.99±0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.54±0.46</td>\n",
       "      <td>0.81±0.38</td>\n",
       "      <td>0.42±0.47</td>\n",
       "      <td>0.88±0.32</td>\n",
       "      <td>0.96±0.18</td>\n",
       "      <td>0.39±0.48</td>\n",
       "      <td>0.35±0.48</td>\n",
       "      <td>0.85±0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49±0.47</td>\n",
       "      <td>0.54±0.48</td>\n",
       "      <td>0.60±0.48</td>\n",
       "      <td>0.99±0.07</td>\n",
       "      <td>0.71±0.44</td>\n",
       "      <td>0.98±0.13</td>\n",
       "      <td>0.64±0.46</td>\n",
       "      <td>0.45±0.48</td>\n",
       "      <td>0.67±0.46</td>\n",
       "      <td>0.63±0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0.44±0.36</td>\n",
       "      <td>0.60±0.31</td>\n",
       "      <td>0.34±0.30</td>\n",
       "      <td>0.82±0.22</td>\n",
       "      <td>0.95±0.12</td>\n",
       "      <td>0.37±0.30</td>\n",
       "      <td>0.35±0.33</td>\n",
       "      <td>0.76±0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38±0.33</td>\n",
       "      <td>0.54±0.29</td>\n",
       "      <td>0.69±0.26</td>\n",
       "      <td>0.94±0.14</td>\n",
       "      <td>0.68±0.26</td>\n",
       "      <td>0.97±0.10</td>\n",
       "      <td>0.44±0.32</td>\n",
       "      <td>0.46±0.40</td>\n",
       "      <td>0.56±0.27</td>\n",
       "      <td>0.66±0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-5</td>\n",
       "      <td>98</td>\n",
       "      <td>0.47±0.27</td>\n",
       "      <td>0.57±0.21</td>\n",
       "      <td>0.28±0.21</td>\n",
       "      <td>0.80±0.18</td>\n",
       "      <td>0.95±0.12</td>\n",
       "      <td>0.37±0.28</td>\n",
       "      <td>0.32±0.25</td>\n",
       "      <td>0.72±0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40±0.25</td>\n",
       "      <td>0.48±0.22</td>\n",
       "      <td>0.68±0.24</td>\n",
       "      <td>0.95±0.11</td>\n",
       "      <td>0.67±0.21</td>\n",
       "      <td>0.96±0.09</td>\n",
       "      <td>0.55±0.26</td>\n",
       "      <td>0.49±0.31</td>\n",
       "      <td>0.47±0.23</td>\n",
       "      <td>0.66±0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6+</td>\n",
       "      <td>60</td>\n",
       "      <td>0.50±0.17</td>\n",
       "      <td>0.53±0.14</td>\n",
       "      <td>0.32±0.19</td>\n",
       "      <td>0.70±0.16</td>\n",
       "      <td>0.90±0.12</td>\n",
       "      <td>0.38±0.19</td>\n",
       "      <td>0.41±0.20</td>\n",
       "      <td>0.72±0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45±0.20</td>\n",
       "      <td>0.55±0.14</td>\n",
       "      <td>0.66±0.18</td>\n",
       "      <td>0.94±0.07</td>\n",
       "      <td>0.63±0.15</td>\n",
       "      <td>0.94±0.06</td>\n",
       "      <td>0.58±0.20</td>\n",
       "      <td>0.54±0.25</td>\n",
       "      <td>0.58±0.19</td>\n",
       "      <td>0.69±0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bins_items_correct_answer  count (prompting, gpt-4o-mini-2024-07-18, n/a)  \\\n",
       "0                         0    150                                0.51±0.50   \n",
       "1                         1    150                                0.54±0.46   \n",
       "2                         2     90                                0.44±0.36   \n",
       "3                       3-5     98                                0.47±0.27   \n",
       "4                        6+     60                                0.50±0.17   \n",
       "\n",
       "  (prompting, gpt-4o-2024-08-06, n/a) (prompting, gpt-4.1-nano, n/a)  \\\n",
       "0                           0.84±0.37                      0.42±0.50   \n",
       "1                           0.81±0.38                      0.42±0.47   \n",
       "2                           0.60±0.31                      0.34±0.30   \n",
       "3                           0.57±0.21                      0.28±0.21   \n",
       "4                           0.53±0.14                      0.32±0.19   \n",
       "\n",
       "  (prompting, gpt-5-mini, n/a) (prompting, gpt-5, n/a)  \\\n",
       "0                    0.95±0.21               0.95±0.21   \n",
       "1                    0.88±0.32               0.96±0.18   \n",
       "2                    0.82±0.22               0.95±0.12   \n",
       "3                    0.80±0.18               0.95±0.12   \n",
       "4                    0.70±0.16               0.90±0.12   \n",
       "\n",
       "  (prompting, claude-3-haiku-20240307, n/a)  \\\n",
       "0                                 0.84±0.37   \n",
       "1                                 0.39±0.48   \n",
       "2                                 0.37±0.30   \n",
       "3                                 0.37±0.28   \n",
       "4                                 0.38±0.19   \n",
       "\n",
       "  (prompting, claude-3-5-sonnet-20240620, n/a)  \\\n",
       "0                                    0.92±0.27   \n",
       "1                                    0.35±0.48   \n",
       "2                                    0.35±0.33   \n",
       "3                                    0.32±0.25   \n",
       "4                                    0.41±0.20   \n",
       "\n",
       "  (prompting, claude-sonnet-4-20250514, n/a)  ...  \\\n",
       "0                                  0.90±0.30  ...   \n",
       "1                                  0.85±0.35  ...   \n",
       "2                                  0.76±0.25  ...   \n",
       "3                                  0.72±0.22  ...   \n",
       "4                                  0.72±0.14  ...   \n",
       "\n",
       "  (prompting, llama-3.1-405b-instruct, n/a)  \\\n",
       "0                                 0.80±0.40   \n",
       "1                                 0.49±0.47   \n",
       "2                                 0.38±0.33   \n",
       "3                                 0.40±0.25   \n",
       "4                                 0.45±0.20   \n",
       "\n",
       "  (prompting, gemini-2.0-flash-001, n/a)  \\\n",
       "0                              0.87±0.33   \n",
       "1                              0.54±0.48   \n",
       "2                              0.54±0.29   \n",
       "3                              0.48±0.22   \n",
       "4                              0.55±0.14   \n",
       "\n",
       "  (prompting, gemini-2.0-flash-thinking-exp-01-21, n/a)  \\\n",
       "0                                          0.91±0.29      \n",
       "1                                          0.60±0.48      \n",
       "2                                          0.69±0.26      \n",
       "3                                          0.68±0.24      \n",
       "4                                          0.66±0.18      \n",
       "\n",
       "  (prompting, gemini-2.5-flash, n/a)  \\\n",
       "0                          0.98±0.14   \n",
       "1                          0.99±0.07   \n",
       "2                          0.94±0.14   \n",
       "3                          0.95±0.11   \n",
       "4                          0.94±0.07   \n",
       "\n",
       "  (prompting, gemini-2.0-pro-exp-02-05, n/a) (prompting, gemini-2.5-pro, n/a)  \\\n",
       "0                                  0.85±0.36                        0.99±0.08   \n",
       "1                                  0.71±0.44                        0.98±0.13   \n",
       "2                                  0.68±0.26                        0.97±0.10   \n",
       "3                                  0.67±0.21                        0.96±0.09   \n",
       "4                                  0.63±0.15                        0.94±0.06   \n",
       "\n",
       "  (prompting, deepseek-chat, n/a) (prompting, deepseek-reasoner, n/a)  \\\n",
       "0                       0.79±0.41                           0.92±0.27   \n",
       "1                       0.64±0.46                           0.45±0.48   \n",
       "2                       0.44±0.32                           0.46±0.40   \n",
       "3                       0.55±0.26                           0.49±0.31   \n",
       "4                       0.58±0.20                           0.54±0.25   \n",
       "\n",
       "  (prompting, grok-4-fast-non-reasoning, n/a)  \\\n",
       "0                                   0.73±0.45   \n",
       "1                                   0.67±0.46   \n",
       "2                                   0.56±0.27   \n",
       "3                                   0.47±0.23   \n",
       "4                                   0.58±0.19   \n",
       "\n",
       "  (prompting, grok-4-fast-reasoning, n/a)  \n",
       "0                               0.99±0.08  \n",
       "1                               0.63±0.48  \n",
       "2                               0.66±0.26  \n",
       "3                               0.66±0.23  \n",
       "4                               0.69±0.12  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epbench.src.results.average_groups import extract_groups\n",
    "nb_events = 200 # select the book of interest (either 20 or 200)\n",
    "relative_to = ['get', 'bins_items_correct_answer'] # select the grouped elements as a list among:\n",
    "# 'get': type of question, among 'all' (simple recall questions), 'latest' (latest state questions), or 'chronological' (chronological questions)\n",
    "# 'bins_items_correct_answer': number of events for this question, binned into {0}, {1}, {2}, {3,4,5}, {6+} chapters\n",
    "# 'cue': type of cue for this question, e.g. (*,*,*,c)\n",
    "# 'retrieval_type': type of trace for this question, e.g. 'Spaces'\n",
    "df_results = extract_groups(df, nb_events, relative_to) # group the results according to `relative_to`\n",
    "\n",
    "# Further filtering, e.g. for selecting only the simple recall questions:\n",
    "df_results = df_results[df_results['get'] == 'all'].drop('get', axis = 1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins_items_correct_answer</th>\n",
       "      <th>count</th>\n",
       "      <th>(prompting, gpt-4o-mini-2024-07-18, n/a)</th>\n",
       "      <th>(prompting, gpt-4o-2024-08-06, n/a)</th>\n",
       "      <th>(prompting, gpt-4.1-nano, n/a)</th>\n",
       "      <th>(prompting, gpt-5-mini, n/a)</th>\n",
       "      <th>(prompting, gpt-5, n/a)</th>\n",
       "      <th>(prompting, claude-3-haiku-20240307, n/a)</th>\n",
       "      <th>(prompting, claude-3-5-sonnet-20240620, n/a)</th>\n",
       "      <th>(prompting, claude-sonnet-4-20250514, n/a)</th>\n",
       "      <th>...</th>\n",
       "      <th>(prompting, llama-3.1-405b-instruct, n/a)</th>\n",
       "      <th>(prompting, gemini-2.0-flash-001, n/a)</th>\n",
       "      <th>(prompting, gemini-2.0-flash-thinking-exp-01-21, n/a)</th>\n",
       "      <th>(prompting, gemini-2.5-flash, n/a)</th>\n",
       "      <th>(prompting, gemini-2.0-pro-exp-02-05, n/a)</th>\n",
       "      <th>(prompting, gemini-2.5-pro, n/a)</th>\n",
       "      <th>(prompting, deepseek-chat, n/a)</th>\n",
       "      <th>(prompting, deepseek-reasoner, n/a)</th>\n",
       "      <th>(prompting, grok-4-fast-non-reasoning, n/a)</th>\n",
       "      <th>(prompting, grok-4-fast-reasoning, n/a)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0.51±0.50</td>\n",
       "      <td>0.84±0.37</td>\n",
       "      <td>0.42±0.50</td>\n",
       "      <td>0.95±0.21</td>\n",
       "      <td>0.95±0.21</td>\n",
       "      <td>0.84±0.37</td>\n",
       "      <td>0.92±0.27</td>\n",
       "      <td>0.90±0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80±0.40</td>\n",
       "      <td>0.87±0.33</td>\n",
       "      <td>0.91±0.29</td>\n",
       "      <td>0.98±0.14</td>\n",
       "      <td>0.85±0.36</td>\n",
       "      <td>0.99±0.08</td>\n",
       "      <td>0.79±0.41</td>\n",
       "      <td>0.92±0.27</td>\n",
       "      <td>0.73±0.45</td>\n",
       "      <td>0.99±0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.54±0.46</td>\n",
       "      <td>0.81±0.38</td>\n",
       "      <td>0.42±0.47</td>\n",
       "      <td>0.88±0.32</td>\n",
       "      <td>0.96±0.18</td>\n",
       "      <td>0.39±0.48</td>\n",
       "      <td>0.35±0.48</td>\n",
       "      <td>0.85±0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49±0.47</td>\n",
       "      <td>0.54±0.48</td>\n",
       "      <td>0.60±0.48</td>\n",
       "      <td>0.99±0.07</td>\n",
       "      <td>0.71±0.44</td>\n",
       "      <td>0.98±0.13</td>\n",
       "      <td>0.64±0.46</td>\n",
       "      <td>0.45±0.48</td>\n",
       "      <td>0.67±0.46</td>\n",
       "      <td>0.63±0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0.44±0.36</td>\n",
       "      <td>0.60±0.31</td>\n",
       "      <td>0.34±0.30</td>\n",
       "      <td>0.82±0.22</td>\n",
       "      <td>0.95±0.12</td>\n",
       "      <td>0.37±0.30</td>\n",
       "      <td>0.35±0.33</td>\n",
       "      <td>0.76±0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38±0.33</td>\n",
       "      <td>0.54±0.29</td>\n",
       "      <td>0.69±0.26</td>\n",
       "      <td>0.94±0.14</td>\n",
       "      <td>0.68±0.26</td>\n",
       "      <td>0.97±0.10</td>\n",
       "      <td>0.44±0.32</td>\n",
       "      <td>0.46±0.40</td>\n",
       "      <td>0.56±0.27</td>\n",
       "      <td>0.66±0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-5</td>\n",
       "      <td>98</td>\n",
       "      <td>0.47±0.27</td>\n",
       "      <td>0.57±0.21</td>\n",
       "      <td>0.28±0.21</td>\n",
       "      <td>0.80±0.18</td>\n",
       "      <td>0.95±0.12</td>\n",
       "      <td>0.37±0.28</td>\n",
       "      <td>0.32±0.25</td>\n",
       "      <td>0.72±0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40±0.25</td>\n",
       "      <td>0.48±0.22</td>\n",
       "      <td>0.68±0.24</td>\n",
       "      <td>0.95±0.11</td>\n",
       "      <td>0.67±0.21</td>\n",
       "      <td>0.96±0.09</td>\n",
       "      <td>0.55±0.26</td>\n",
       "      <td>0.49±0.31</td>\n",
       "      <td>0.47±0.23</td>\n",
       "      <td>0.66±0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6+</td>\n",
       "      <td>60</td>\n",
       "      <td>0.50±0.17</td>\n",
       "      <td>0.53±0.14</td>\n",
       "      <td>0.32±0.19</td>\n",
       "      <td>0.70±0.16</td>\n",
       "      <td>0.90±0.12</td>\n",
       "      <td>0.38±0.19</td>\n",
       "      <td>0.41±0.20</td>\n",
       "      <td>0.72±0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45±0.20</td>\n",
       "      <td>0.55±0.14</td>\n",
       "      <td>0.66±0.18</td>\n",
       "      <td>0.94±0.07</td>\n",
       "      <td>0.63±0.15</td>\n",
       "      <td>0.94±0.06</td>\n",
       "      <td>0.58±0.20</td>\n",
       "      <td>0.54±0.25</td>\n",
       "      <td>0.58±0.19</td>\n",
       "      <td>0.69±0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bins_items_correct_answer  count (prompting, gpt-4o-mini-2024-07-18, n/a)  \\\n",
       "0                         0    150                                0.51±0.50   \n",
       "1                         1    150                                0.54±0.46   \n",
       "2                         2     90                                0.44±0.36   \n",
       "3                       3-5     98                                0.47±0.27   \n",
       "4                        6+     60                                0.50±0.17   \n",
       "\n",
       "  (prompting, gpt-4o-2024-08-06, n/a) (prompting, gpt-4.1-nano, n/a)  \\\n",
       "0                           0.84±0.37                      0.42±0.50   \n",
       "1                           0.81±0.38                      0.42±0.47   \n",
       "2                           0.60±0.31                      0.34±0.30   \n",
       "3                           0.57±0.21                      0.28±0.21   \n",
       "4                           0.53±0.14                      0.32±0.19   \n",
       "\n",
       "  (prompting, gpt-5-mini, n/a) (prompting, gpt-5, n/a)  \\\n",
       "0                    0.95±0.21               0.95±0.21   \n",
       "1                    0.88±0.32               0.96±0.18   \n",
       "2                    0.82±0.22               0.95±0.12   \n",
       "3                    0.80±0.18               0.95±0.12   \n",
       "4                    0.70±0.16               0.90±0.12   \n",
       "\n",
       "  (prompting, claude-3-haiku-20240307, n/a)  \\\n",
       "0                                 0.84±0.37   \n",
       "1                                 0.39±0.48   \n",
       "2                                 0.37±0.30   \n",
       "3                                 0.37±0.28   \n",
       "4                                 0.38±0.19   \n",
       "\n",
       "  (prompting, claude-3-5-sonnet-20240620, n/a)  \\\n",
       "0                                    0.92±0.27   \n",
       "1                                    0.35±0.48   \n",
       "2                                    0.35±0.33   \n",
       "3                                    0.32±0.25   \n",
       "4                                    0.41±0.20   \n",
       "\n",
       "  (prompting, claude-sonnet-4-20250514, n/a)  ...  \\\n",
       "0                                  0.90±0.30  ...   \n",
       "1                                  0.85±0.35  ...   \n",
       "2                                  0.76±0.25  ...   \n",
       "3                                  0.72±0.22  ...   \n",
       "4                                  0.72±0.14  ...   \n",
       "\n",
       "  (prompting, llama-3.1-405b-instruct, n/a)  \\\n",
       "0                                 0.80±0.40   \n",
       "1                                 0.49±0.47   \n",
       "2                                 0.38±0.33   \n",
       "3                                 0.40±0.25   \n",
       "4                                 0.45±0.20   \n",
       "\n",
       "  (prompting, gemini-2.0-flash-001, n/a)  \\\n",
       "0                              0.87±0.33   \n",
       "1                              0.54±0.48   \n",
       "2                              0.54±0.29   \n",
       "3                              0.48±0.22   \n",
       "4                              0.55±0.14   \n",
       "\n",
       "  (prompting, gemini-2.0-flash-thinking-exp-01-21, n/a)  \\\n",
       "0                                          0.91±0.29      \n",
       "1                                          0.60±0.48      \n",
       "2                                          0.69±0.26      \n",
       "3                                          0.68±0.24      \n",
       "4                                          0.66±0.18      \n",
       "\n",
       "  (prompting, gemini-2.5-flash, n/a)  \\\n",
       "0                          0.98±0.14   \n",
       "1                          0.99±0.07   \n",
       "2                          0.94±0.14   \n",
       "3                          0.95±0.11   \n",
       "4                          0.94±0.07   \n",
       "\n",
       "  (prompting, gemini-2.0-pro-exp-02-05, n/a) (prompting, gemini-2.5-pro, n/a)  \\\n",
       "0                                  0.85±0.36                        0.99±0.08   \n",
       "1                                  0.71±0.44                        0.98±0.13   \n",
       "2                                  0.68±0.26                        0.97±0.10   \n",
       "3                                  0.67±0.21                        0.96±0.09   \n",
       "4                                  0.63±0.15                        0.94±0.06   \n",
       "\n",
       "  (prompting, deepseek-chat, n/a) (prompting, deepseek-reasoner, n/a)  \\\n",
       "0                       0.79±0.41                           0.92±0.27   \n",
       "1                       0.64±0.46                           0.45±0.48   \n",
       "2                       0.44±0.32                           0.46±0.40   \n",
       "3                       0.55±0.26                           0.49±0.31   \n",
       "4                       0.58±0.20                           0.54±0.25   \n",
       "\n",
       "  (prompting, grok-4-fast-non-reasoning, n/a)  \\\n",
       "0                                   0.73±0.45   \n",
       "1                                   0.67±0.46   \n",
       "2                                   0.56±0.27   \n",
       "3                                   0.47±0.23   \n",
       "4                                   0.58±0.19   \n",
       "\n",
       "  (prompting, grok-4-fast-reasoning, n/a)  \n",
       "0                               0.99±0.08  \n",
       "1                               0.63±0.48  \n",
       "2                               0.66±0.26  \n",
       "3                               0.66±0.23  \n",
       "4                               0.69±0.12  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epbench.src.evaluation.ranking import get_simple_results\n",
    "nb_events = 200 # select the book of interest (either 20 or 200)\n",
    "df_results_simple = get_simple_results(df, nb_events)\n",
    "df_results_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Summarizing table column \"Simple Recall\" in the github (updated with the latest changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(prompting, gemini-2.5-pro, n/a)                         0.968\n",
       "(prompting, gemini-2.5-flash, n/a)                       0.960\n",
       "(prompting, gpt-5, n/a)                                  0.942\n",
       "(prompting, gpt-5-mini, n/a)                             0.830\n",
       "(prompting, claude-sonnet-4-20250514, n/a)               0.790\n",
       "(prompting, grok-4-fast-reasoning, n/a)                  0.726\n",
       "(prompting, gemini-2.0-flash-thinking-exp-01-21, n/a)    0.708\n",
       "(prompting, gemini-2.0-pro-exp-02-05, n/a)               0.708\n",
       "(prompting, gpt-4o-2024-08-06, n/a)                      0.670\n",
       "(prompting, grok-4-fast-non-reasoning, n/a)              0.602\n",
       "(prompting, deepseek-chat, n/a)                          0.600\n",
       "(prompting, gemini-2.0-flash-001, n/a)                   0.596\n",
       "(prompting, deepseek-reasoner, n/a)                      0.572\n",
       "(prompting, llama-3.1-405b-instruct, n/a)                0.504\n",
       "(prompting, gpt-4o-mini-2024-07-18, n/a)                 0.492\n",
       "(prompting, claude-3-5-sonnet-20240620, n/a)             0.470\n",
       "(prompting, claude-3-haiku-20240307, n/a)                0.470\n",
       "(prompting, o3-mini, n/a)                                0.424\n",
       "(prompting, o1, n/a)                                     0.384\n",
       "(prompting, gpt-4.1-nano, n/a)                           0.356\n",
       "(prompting, o1-mini, n/a)                                0.300\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epbench.src.evaluation.ranking import simple_recall_score\n",
    "simple_recall_score(df_results_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chronological score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <th>gpt-5</th>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <th>claude-sonnet-4-20250514</th>\n",
       "      <th>gpt-5-mini</th>\n",
       "      <th>gemini-2-pro</th>\n",
       "      <th>grok-4-fast-reasoning</th>\n",
       "      <th>gpt-4o</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <th>cl-3-haiku</th>\n",
       "      <th>...</th>\n",
       "      <th>gpt-4.1-nano</th>\n",
       "      <th>deepseek-reasoner</th>\n",
       "      <th>cl-3.5-sonnet</th>\n",
       "      <th>o1-mini</th>\n",
       "      <th>o1</th>\n",
       "      <th>o3-mini</th>\n",
       "      <th>llama-3.1</th>\n",
       "      <th>gemini-2-flash</th>\n",
       "      <th>deepseek-chat</th>\n",
       "      <th>grok-4-fast-non-reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Latest</th>\n",
       "      <td>89.77%</td>\n",
       "      <td>92.31%</td>\n",
       "      <td>92.46%</td>\n",
       "      <td>57.62%</td>\n",
       "      <td>67.92%</td>\n",
       "      <td>45.15%</td>\n",
       "      <td>45.92%</td>\n",
       "      <td>35.69%</td>\n",
       "      <td>12.77%</td>\n",
       "      <td>16.77%</td>\n",
       "      <td>...</td>\n",
       "      <td>15.38%</td>\n",
       "      <td>29.46%</td>\n",
       "      <td>18.0%</td>\n",
       "      <td>6.54%</td>\n",
       "      <td>10.38%</td>\n",
       "      <td>8.85%</td>\n",
       "      <td>25.77%</td>\n",
       "      <td>34.54%</td>\n",
       "      <td>20.69%</td>\n",
       "      <td>24.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>74.36%</td>\n",
       "      <td>69.23%</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>28.21%</td>\n",
       "      <td>20.51%</td>\n",
       "      <td>12.82%</td>\n",
       "      <td>10.26%</td>\n",
       "      <td>10.26%</td>\n",
       "      <td>7.69%</td>\n",
       "      <td>5.13%</td>\n",
       "      <td>...</td>\n",
       "      <td>2.56%</td>\n",
       "      <td>2.56%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kendall τ</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gemini-2.5-flash   gpt-5 gemini-2.5-pro claude-sonnet-4-20250514  \\\n",
       "Latest              89.77%  92.31%         92.46%                   57.62%   \n",
       "All                 74.36%  69.23%         66.67%                   28.21%   \n",
       "Kendall τ             0.99    0.99            1.0                     0.27   \n",
       "\n",
       "          gpt-5-mini gemini-2-pro grok-4-fast-reasoning  gpt-4o gpt-4o-mini  \\\n",
       "Latest        67.92%       45.15%                45.92%  35.69%      12.77%   \n",
       "All           20.51%       12.82%                10.26%  10.26%       7.69%   \n",
       "Kendall τ        1.0          1.0                   1.0     0.5        0.33   \n",
       "\n",
       "          cl-3-haiku  ... gpt-4.1-nano deepseek-reasoner cl-3.5-sonnet  \\\n",
       "Latest        16.77%  ...       15.38%            29.46%         18.0%   \n",
       "All            5.13%  ...        2.56%             2.56%          0.0%   \n",
       "Kendall τ        1.0  ...          1.0              -1.0           NaN   \n",
       "\n",
       "          o1-mini      o1 o3-mini llama-3.1 gemini-2-flash deepseek-chat  \\\n",
       "Latest      6.54%  10.38%   8.85%    25.77%         34.54%        20.69%   \n",
       "All          0.0%    0.0%    0.0%      0.0%           0.0%          0.0%   \n",
       "Kendall τ     NaN     NaN     NaN       NaN            NaN           NaN   \n",
       "\n",
       "          grok-4-fast-non-reasoning  \n",
       "Latest                       24.31%  \n",
       "All                            0.0%  \n",
       "Kendall τ                       NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epbench.src.evaluation.ranking import get_kendall_tau_results\n",
    "nb_events = 200\n",
    "kendall_tau_results = get_kendall_tau_results(df, nb_events)\n",
    "kendall_tau_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Summarizing table column \"Chronological Awareness\" in the github (updated with the latest changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gemini-2.5-flash             0.817\n",
       "gpt-5                        0.804\n",
       "gemini-2.5-pro               0.796\n",
       "gpt-5-mini                   0.442\n",
       "claude-sonnet-4-20250514     0.326\n",
       "gemini-2-pro                 0.290\n",
       "gemini-2-flash-thinking      0.288\n",
       "grok-4-fast-reasoning        0.281\n",
       "gpt-4o                       0.204\n",
       "gemini-2-flash               0.173\n",
       "deepseek-reasoner            0.147\n",
       "llama-3.1                    0.129\n",
       "grok-4-fast-non-reasoning    0.122\n",
       "cl-3-haiku                   0.109\n",
       "deepseek-chat                0.103\n",
       "cl-3.5-sonnet                0.090\n",
       "gpt-4.1-nano                 0.090\n",
       "gpt-4o-mini                  0.077\n",
       "o1                           0.052\n",
       "o3-mini                      0.044\n",
       "o1-mini                      0.033\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epbench.src.evaluation.ranking import chronological_awareness\n",
    "chronological_awareness(kendall_tau_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct computation of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>🎯 Simple Recall</th>\n",
       "      <th>⏱️ Chronological Awareness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-5</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-5-mini</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-sonnet-4-20250514</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grok-4-fast-reasoning</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2-flash-thinking</th>\n",
       "      <td>0.708</td>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2-pro</th>\n",
       "      <td>0.708</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grok-4-fast-non-reasoning</th>\n",
       "      <td>0.602</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-chat</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2-flash</th>\n",
       "      <td>0.596</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-reasoner</th>\n",
       "      <td>0.572</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.1</th>\n",
       "      <td>0.504</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>0.492</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cl-3.5-sonnet</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cl-3-haiku</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3-mini</th>\n",
       "      <td>0.424</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1</th>\n",
       "      <td>0.384</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4.1-nano</th>\n",
       "      <td>0.356</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1-mini</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           🎯 Simple Recall  ⏱️ Chronological Awareness\n",
       "gemini-2.5-pro                       0.968                       0.796\n",
       "gemini-2.5-flash                     0.960                       0.817\n",
       "gpt-5                                0.942                       0.804\n",
       "gpt-5-mini                           0.830                       0.442\n",
       "claude-sonnet-4-20250514             0.790                       0.326\n",
       "grok-4-fast-reasoning                0.726                       0.281\n",
       "gemini-2-flash-thinking              0.708                       0.288\n",
       "gemini-2-pro                         0.708                       0.290\n",
       "gpt-4o                               0.670                       0.204\n",
       "grok-4-fast-non-reasoning            0.602                       0.122\n",
       "deepseek-chat                        0.600                       0.103\n",
       "gemini-2-flash                       0.596                       0.173\n",
       "deepseek-reasoner                    0.572                       0.147\n",
       "llama-3.1                            0.504                       0.129\n",
       "gpt-4o-mini                          0.492                       0.077\n",
       "cl-3.5-sonnet                        0.470                       0.090\n",
       "cl-3-haiku                           0.470                       0.109\n",
       "o3-mini                              0.424                       0.044\n",
       "o1                                   0.384                       0.052\n",
       "gpt-4.1-nano                         0.356                       0.090\n",
       "o1-mini                              0.300                       0.033"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epbench.src.evaluation.ranking import get_final_scores_table\n",
    "\n",
    "nb_events = 200 # select the book of interest (either 20 or 200)\n",
    "get_final_scores_table(df, nb_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>🎯 Simple Recall (short book)</th>\n",
       "      <th>⏱️ Chronological Awareness (short book)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deepseek-reasoner</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grok-4-fast-reasoning</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-5</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-sonnet-4-20250514</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-5-mini</th>\n",
       "      <td>0.962</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2-flash-thinking</th>\n",
       "      <td>0.962</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2-pro</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3-mini</th>\n",
       "      <td>0.945</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1-mini</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grok-4-fast-non-reasoning</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-5-nano</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2-flash</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-chat</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.1</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cl-3.5-sonnet</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cl-3-haiku</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4.1-nano</th>\n",
       "      <td>0.695</td>\n",
       "      <td>0.287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           🎯 Simple Recall (short book)  \\\n",
       "deepseek-reasoner                                 0.988   \n",
       "gemini-2.5-pro                                    0.982   \n",
       "grok-4-fast-reasoning                             0.982   \n",
       "gemini-2.5-flash                                  0.980   \n",
       "gpt-5                                             0.978   \n",
       "o1                                                0.978   \n",
       "claude-sonnet-4-20250514                          0.972   \n",
       "gpt-5-mini                                        0.962   \n",
       "gemini-2-flash-thinking                           0.962   \n",
       "gemini-2-pro                                      0.950   \n",
       "o3-mini                                           0.945   \n",
       "o1-mini                                           0.935   \n",
       "grok-4-fast-non-reasoning                         0.930   \n",
       "gpt-5-nano                                        0.920   \n",
       "gemini-2-flash                                    0.915   \n",
       "deepseek-chat                                     0.910   \n",
       "gpt-4o                                            0.908   \n",
       "llama-3.1                                         0.895   \n",
       "cl-3.5-sonnet                                     0.845   \n",
       "gpt-4o-mini                                       0.803   \n",
       "cl-3-haiku                                        0.698   \n",
       "gpt-4.1-nano                                      0.695   \n",
       "\n",
       "                           ⏱️ Chronological Awareness (short book)  \n",
       "deepseek-reasoner                                            0.964  \n",
       "gemini-2.5-pro                                               0.948  \n",
       "grok-4-fast-reasoning                                        0.932  \n",
       "gemini-2.5-flash                                             0.916  \n",
       "gpt-5                                                        0.948  \n",
       "o1                                                           0.948  \n",
       "claude-sonnet-4-20250514                                     0.657  \n",
       "gpt-5-mini                                                   0.948  \n",
       "gemini-2-flash-thinking                                      0.967  \n",
       "gemini-2-pro                                                 0.186  \n",
       "o3-mini                                                      0.809  \n",
       "o1-mini                                                      0.809  \n",
       "grok-4-fast-non-reasoning                                    0.512  \n",
       "gpt-5-nano                                                   0.764  \n",
       "gemini-2-flash                                               0.163  \n",
       "deepseek-chat                                                0.481  \n",
       "gpt-4o                                                       0.182  \n",
       "llama-3.1                                                    0.297  \n",
       "cl-3.5-sonnet                                                0.329  \n",
       "gpt-4o-mini                                                  0.256  \n",
       "cl-3-haiku                                                   0.185  \n",
       "gpt-4.1-nano                                                 0.287  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_events = 20\n",
    "get_final_scores_table(df, nb_events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
